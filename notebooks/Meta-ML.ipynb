{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82383928-ec0b-4f18-a522-a30543e9f058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import anthropic\n",
    "anthropic_client = anthropic.Anthropic(api_key=open('ANTHROPIC_API_KEY.txt').read().strip())\n",
    "\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sys\n",
    "import multiprocessing\n",
    "from multiprocessing import Process\n",
    "import concurrent.futures\n",
    "from tqdm.notebook import tqdm\n",
    "# import metaomni as mo\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_california_housing, fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "import traceback\n",
    "import os\n",
    "import importlib.util\n",
    "import time\n",
    "\n",
    "import importlib\n",
    "sys.path.append('/Users/jeremynixon/Dropbox/python_new/Misc/omega_research/metaomni')\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the Wine dataset\n",
    "wine = load_wine()\n",
    "X, y = wine.data, wine.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac3ad2f6-c8ef-48cf-8063-a06890cc8029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=4000,\n",
    "        temperature=0,\n",
    "        system=\"You are a world-class research engineer.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "def extract_code_snippets(text):\n",
    "    pattern = r'```(?:python)?\\n(.*?)```'\n",
    "    snippets = re.findall(pattern, text, re.DOTALL)\n",
    "    return [snippet.strip() for snippet in snippets]\n",
    "\n",
    "def save_first_snippet(snippets, filename):\n",
    "    if snippets:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(snippets[0])\n",
    "        print(f\"First code snippet saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No code snippets found\")\n",
    "\n",
    "def extract_name(text):\n",
    "    pattern = r'<name>(.*?)</name>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604c004-1e09-4355-a724-d3b264a3d1aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75af4f76-3fcf-4a27-b95d-c9fb9bf5bb32",
   "metadata": {},
   "source": [
    "# Dataset Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2060633f-fa3a-43fc-a9c2-352e3c5439f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# iris = load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# # Load the Wine dataset\n",
    "# wine = load_wine()\n",
    "# X, y = wine.data, wine.target\n",
    "\n",
    "# # Split the dataset into training and testing sets\n",
    "# x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08855dfb-8c31-4476-adcd-dd26ed0e584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen(prompt):\n",
    "    message = anthropic_client.messages.create(\n",
    "        model=\"claude-3-5-sonnet-20240620\",\n",
    "        max_tokens=4000,\n",
    "        temperature=0,\n",
    "        system=\"You are a world-class research engineer.\",\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": [\n",
    "                    {\n",
    "                        \"type\": \"text\",\n",
    "                        \"text\": prompt\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return message.content[0].text\n",
    "\n",
    "def extract_code_snippets(text):\n",
    "    pattern = r'```(?:python)?\\n(.*?)```'\n",
    "    snippets = re.findall(pattern, text, re.DOTALL)\n",
    "    return [snippet.strip() for snippet in snippets]\n",
    "\n",
    "def save_first_snippet(snippets, filename):\n",
    "    if snippets:\n",
    "        with open(filename, 'w') as file:\n",
    "            file.write(snippets[0])\n",
    "        print(f\"First code snippet saved to {filename}\")\n",
    "    else:\n",
    "        print(\"No code snippets found\")\n",
    "\n",
    "def extract_name(text):\n",
    "    pattern = r'<name>(.*?)</name>'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def add_import_to_init(init_file_path, import_string):\n",
    "    # Read the current contents of the file\n",
    "    with open(init_file_path, 'r') as file:\n",
    "        content = file.read()\n",
    "\n",
    "    # Check if the import statement already exists\n",
    "    if import_string not in content:\n",
    "        # If it doesn't exist, add it to the end of the file\n",
    "        with open(init_file_path, 'a') as file:\n",
    "            file.write('\\n' + import_string)\n",
    "        print(f\"Added {import_string} to {init_file_path}\")\n",
    "    else:\n",
    "        print(f\"{import_string} already exists in {init_file_path}\")\n",
    "\n",
    "# model = 'logistic regression'\n",
    "\n",
    "def execute(filename, class_name, model, count=1):\n",
    "    if count > 2:\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "            return\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    EXECUTION_STRINGS = f\"\"\"importlib.reload(metaomni)\n",
    "ml_model = metaomni.{filename.split('.py')[0]}.{class_name}()\n",
    "ml_model.fit(x_train, y_train)\n",
    "preds = ml_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(class_name, accuracy)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        exec(EXECUTION_STRINGS)\n",
    "    except Exception as e:\n",
    "        error_message = traceback.format_exc()\n",
    "        print(\"Hit error: \", error_message)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Existing code:\n",
    "        {open(f'metaomni/{filename}', 'r').read()}\n",
    "    \n",
    "        Error message on original execution:\n",
    "        {e}\n",
    "    \n",
    "        Full traceback:\n",
    "        {error_message}\n",
    "    \n",
    "        Given the original code and this error, rewrite a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "        implementation = gen(prompt)\n",
    "        \n",
    "        snippets = extract_code_snippets(implementation)\n",
    "        save_first_snippet(snippets, 'metaomni/' + filename)\n",
    "        execute(filename, class_name, model, count+1)\n",
    "\n",
    "def genML(model):\n",
    "    class_name_prompt = f\"\"\"Write a succinct pythonic class name for a model with name {model}, putting the name between the XML tags <name>Insert Class Name of Model Here</name>\"\"\"\n",
    "    class_name = extract_name(gen(class_name_prompt))\n",
    "    \n",
    "    filename_prompt = f\"\"\"Write a succinct pythonic file name for a model with name {model}, putting the file name between the XML tags <name>Insert Class Name of File Here</name>\"\"\"\n",
    "    filename = extract_name(gen(filename_prompt))\n",
    "    \n",
    "    import_string = f\"import {filename.split('.py')[0]}\"\n",
    "    \n",
    "    prompt = f\"\"\"Write a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "    implementation = gen(prompt)\n",
    "    \n",
    "    snippets = extract_code_snippets(implementation)\n",
    "    save_first_snippet(snippets, 'metaomni/' + filename)\n",
    "    add_import_to_init('metaomni/__init__.py', import_string)\n",
    "    execute(filename, class_name, model, count=1)\n",
    "    return (filename, class_name)\n",
    "\n",
    "def parallel_genML(prompt_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(genML, prompt_list), total=len(prompt_list)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d8ea084-2bf8-4640-9f5e-e4058b1e8d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "004ccfed-6099-4a04-b6dc-1e5388483e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_wine\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, roc_auc_score, average_precision_score, cohen_kappa_score\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, load_diabetes, fetch_california_housing, fetch_olivetti_faces, fetch_20newsgroups, fetch_covtype, fetch_kddcup99\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "def evaluate_model(model, dataset_name, test_size=0.2):\n",
    "    if dataset_name == \"Iris\":\n",
    "        data = load_iris()\n",
    "    elif dataset_name == \"Wine\":\n",
    "        data = load_wine()\n",
    "    elif dataset_name == \"Breast Cancer\":\n",
    "        data = load_breast_cancer()\n",
    "    elif dataset_name == \"Digits\":\n",
    "        data = load_digits()\n",
    "    elif dataset_name == \"Diabetes\":\n",
    "        data = load_diabetes()\n",
    "    elif dataset_name == \"California Housing\":\n",
    "        data = fetch_california_housing()\n",
    "    elif dataset_name == \"Olivetti Faces\":\n",
    "        data = fetch_olivetti_faces()\n",
    "    # 20 Newsgroups returns text data in the result, even for classification\n",
    "    # elif dataset_name == \"20 Newsgroups\":\n",
    "    #     newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "    #     return newsgroups.data, newsgroups.target\n",
    "    elif dataset_name == \"Covertype\":\n",
    "        data = fetch_covtype()\n",
    "    elif dataset_name == \"KDD Cup 1999\":\n",
    "        data = fetch_kddcup99()\n",
    "    elif dataset_name == \"Abalone\":\n",
    "        data = fetch_openml(name='abalone', version=1, as_frame=False)\n",
    "    # Adult has NaNs\n",
    "    # elif dataset_name == \"Adult\":\n",
    "    #     data = fetch_openml('adult', version=2, as_frame=False)\n",
    "    # MNIST is too slow, and is an image dataset\n",
    "    # elif dataset_name == \"MNIST\":\n",
    "    #     data = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown dataset: {dataset_name}\")\n",
    "        \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "    \n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    kappa = cohen_kappa_score(y_test, y_pred)\n",
    "    cv_scores = cross_val_score(model, X_train, y_train, cv=5)\n",
    "    \n",
    "    # Initialize results dictionary\n",
    "    results = {\n",
    "        \"dataset\": dataset_name,\n",
    "        \"model\": model.__class__.__name__,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_score\": f1,\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"cohen_kappa\": kappa,\n",
    "        \"cross_val_scores\": cv_scores,\n",
    "        \"mean_cv_score\": cv_scores.mean(),\n",
    "        \"cv_score_std\": cv_scores.std()\n",
    "    }\n",
    "    \n",
    "    # Calculate ROC AUC and Average Precision for binary classification\n",
    "    if len(np.unique(y)) == 2:\n",
    "        y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "        results[\"roc_auc\"] = roc_auc_score(y_test, y_pred_proba)\n",
    "        results[\"average_precision\"] = average_precision_score(y_test, y_pred_proba)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "# from sklearn.datasets import load_iris\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# \n",
    "# # Load data\n",
    "# iris = load_iris()\n",
    "# X, y = iris.data, iris.target\n",
    "# \n",
    "# # Create and evaluate model\n",
    "# model = LogisticRegression()\n",
    "# results = evaluate_model(model, X, y, \"Iris Dataset\")\n",
    "# \n",
    "# # Print results\n",
    "# for key, value in results.items():\n",
    "#     print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78568193-8fc8-4e57-9c06-e3b9ceeaa3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if dataset_name == \"Iris\":\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bedcdeb-96c9-45d9-9805-5877b1fb8a5b",
   "metadata": {},
   "source": [
    "# Standard Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90d66b07-5a98-459e-9eb4-ab683c0f15b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Decision Tree', DecisionTreeClassifier())\n",
      "Time =  0.001516103744506836\n",
      "Succeeded at : Wine 0.8888888888888888\n",
      "Succeeded at : Breast Cancer 0.8888888888888888\n",
      "Succeeded at : Digits 0.9722222222222222\n",
      "Succeeded at : Diabetes 0.9444444444444444\n",
      "Succeeded at : Covertype 0.8888888888888888\n",
      "Succeeded at : Abalone 0.9444444444444444\n",
      "('Gradient Boosting', GradientBoostingClassifier())\n",
      "Time =  0.43578624725341797\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Wine 0.9722222222222222\n",
      "Succeeded at : Breast Cancer 0.9722222222222222\n",
      "Succeeded at : Digits 0.9166666666666666\n",
      "Succeeded at : Diabetes 0.9722222222222222\n",
      "Succeeded at : Covertype 0.8888888888888888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Abalone 0.8333333333333334\n",
      "('K-Nearest Neighbors', KNeighborsClassifier())\n",
      "Time =  5.813526153564453\n",
      "Succeeded at : Wine 0.6944444444444444\n",
      "Succeeded at : Breast Cancer 0.6666666666666666\n",
      "Succeeded at : Digits 0.6666666666666666\n",
      "Succeeded at : Diabetes 0.6666666666666666\n",
      "Succeeded at : Covertype 0.5833333333333334\n",
      "Succeeded at : Abalone 0.6666666666666666\n",
      "('Support Vector Machine', SVC())\n",
      "Time =  6.269675970077515\n",
      "Succeeded at : Wine 0.5833333333333334\n",
      "Succeeded at : Breast Cancer 0.6111111111111112\n",
      "Succeeded at : Digits 0.6666666666666666\n",
      "Succeeded at : Diabetes 0.7777777777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Covertype 0.7777777777777778\n",
      "Succeeded at : Abalone 0.6111111111111112\n",
      "('Gaussian Naive Bayes', GaussianNB())\n",
      "Time =  6.68185019493103\n",
      "Succeeded at : Wine 0.9722222222222222\n",
      "Succeeded at : Breast Cancer 1.0\n",
      "Succeeded at : Digits 1.0\n",
      "Succeeded at : Diabetes 0.9444444444444444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Covertype 1.0\n",
      "Succeeded at : Abalone 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "models = [\n",
    "    (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "    # (\"Random Forest\", RandomForestClassifier()),\n",
    "    (\"Gradient Boosting\", GradientBoostingClassifier()),\n",
    "    (\"K-Nearest Neighbors\", KNeighborsClassifier()),\n",
    "    (\"Support Vector Machine\", SVC()),\n",
    "    # (\"Logistic Regression\", LogisticRegression()),\n",
    "    (\"Gaussian Naive Bayes\", GaussianNB())\n",
    "]\n",
    "\n",
    "dataset_names = [\n",
    "    # \"Iris\",\n",
    "    \"Wine\",\n",
    "    \"Breast Cancer\",\n",
    "    \"Digits\",\n",
    "    \"Diabetes\",\n",
    "    # \"California Housing\",\n",
    "    # \"Olivetti Faces\",\n",
    "    \"Covertype\",\n",
    "    # \"KDD Cup 1999\",\n",
    "    \"Abalone\"\n",
    "]\n",
    "\n",
    "table_overall = []\n",
    "\n",
    "start = time.time()\n",
    "for m in models:\n",
    "    table_model = []\n",
    "    print(m)\n",
    "    print(\"Time = \", time.time()-start)\n",
    "    for d in dataset_names:\n",
    "        try:\n",
    "            result = evaluate_model(m[1], d)\n",
    "            print(\"Succeeded at :\", d, result['accuracy'])\n",
    "            table_model.append(result['accuracy'])\n",
    "        except Exception as e:\n",
    "            print(\"Failed at \", d, \"with error\", e)\n",
    "    table_overall.append(table_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e3794e-695a-4636-8ca8-7fedf0b4dc0e",
   "metadata": {},
   "source": [
    "## Latex Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4df18314-2cd7-47fe-8246-46fa7028daec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "table_df = pd.DataFrame(table_overall)\n",
    "table_df.columns = dataset_names\n",
    "table_df.index = [m[0] for m in models]\n",
    "latex_table = table_df.to_latex(index=False)\n",
    "# To save the LaTeX table to a file:\n",
    "with open('table2.tex', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b496a4ac-08ae-4fe6-9bec-cb2f7a586f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_33383/4080202410.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = table_df.to_latex(index=False)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab90db3-88be-4679-b871-6c27194d6508",
   "metadata": {},
   "outputs": [],
   "source": [
    "[m[0] for m in models]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7613bf30-2364-4b82-97df-1c2e46c8e556",
   "metadata": {},
   "source": [
    "# AlgoGen KNN Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9ae300e1-1771-4bf7-8d4c-c7f0331bd7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('KNeighborsClassifier', mo.KNeighborsClassifier()),\n",
    "    # ('BalancedSimDissimKNN', mo.BalancedSimDissimKNN()),\n",
    "    # ('BiasVarianceOptimizedKNNEnsemble', mo.BiasVarianceOptimizedKNNEnsemble()),\n",
    "    # ('CompressibilitySimilarityKNN', mo.CompressibilitySimilarityKNN()),\n",
    "    # ('DirectionalWeightedKNN', mo.DirectionalWeightedKNN()),\n",
    "    # ('EntropyGuidedKNN', mo.EntropyGuidedKNN()),\n",
    "    ('HybridKNNClassifier', mo.HybridKNNClassifier()),\n",
    "    # ('InteractionAwareKNN', mo.InteractionAwareKNN()),\n",
    "    ('MultiLevelAbstractionKNN', mo.MultiLevelAbstractionKNN()),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5228eb4d-cec2-45d6-ad32-ec25d25d1240",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5698e707-f619-4ea3-826f-14a1aaefdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('KNeighborsClassifier', KNeighborsClassifier())\n",
      "Time =  0.002562999725341797\n",
      "Succeeded at : Wine 0.75\n",
      "Succeeded at : Breast Cancer 0.6666666666666666\n",
      "Succeeded at : Digits 0.6666666666666666\n",
      "Succeeded at : Diabetes 0.6666666666666666\n",
      "Succeeded at : Covertype 0.6666666666666666\n",
      "Succeeded at : Abalone 0.6111111111111112\n",
      "('HybridKNNClassifier', HybridKNNClassifier())\n",
      "Time =  0.43250203132629395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Wine 1.0\n",
      "Succeeded at : Breast Cancer 1.0\n",
      "Succeeded at : Digits 0.9444444444444444\n",
      "Succeeded at : Diabetes 1.0\n",
      "Succeeded at : Covertype 0.9722222222222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Succeeded at : Abalone 0.9166666666666666\n",
      "('MultiLevelAbstractionKNN', MultiLevelAbstractionKNN(abstraction_ratios=[0.1, 0.3, 1.0]))\n",
      "Time =  9.803020000457764\n",
      "Succeeded at : Wine 0.9444444444444444\n",
      "Succeeded at : Breast Cancer 0.8888888888888888\n",
      "Succeeded at : Digits 0.9166666666666666\n",
      "Succeeded at : Diabetes 0.9722222222222222\n",
      "Succeeded at : Covertype 0.9444444444444444\n",
      "Succeeded at : Abalone 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# models = [\n",
    "#     (\"Decision Tree\", DecisionTreeClassifier()),\n",
    "#     # (\"Random Forest\", RandomForestClassifier()),\n",
    "#     (\"Gradient Boosting\", GradientBoostingClassifier()),\n",
    "#     (\"K-Nearest Neighbors\", KNeighborsClassifier()),\n",
    "#     (\"Support Vector Machine\", SVC()),\n",
    "#     (\"Logistic Regression\", LogisticRegression()),\n",
    "#     (\"Gaussian Naive Bayes\", GaussianNB())\n",
    "# ]\n",
    "\n",
    "dataset_names = [\n",
    "    # \"Iris\",\n",
    "    \"Wine\",\n",
    "    \"Breast Cancer\",\n",
    "    \"Digits\",\n",
    "    \"Diabetes\",\n",
    "    # \"California Housing\",\n",
    "    # \"Olivetti Faces\",\n",
    "    \"Covertype\",\n",
    "    # \"KDD Cup 1999\",\n",
    "    \"Abalone\"\n",
    "]\n",
    "\n",
    "table_overall = []\n",
    "\n",
    "start = time.time()\n",
    "for m in models:\n",
    "    table_model = []\n",
    "    print(m)\n",
    "    print(\"Time = \", time.time()-start)\n",
    "    for d in dataset_names:\n",
    "        try:\n",
    "            result = evaluate_model(m[1], d)\n",
    "            print(\"Succeeded at :\", d, result['accuracy'])\n",
    "            table_model.append(result['accuracy'])\n",
    "        except Exception as e:\n",
    "            print(\"Failed at \", d, \"with error\", e)\n",
    "            table_model.append(0.0)\n",
    "    table_overall.append(table_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "5181d73c-404c-4d8f-b8fa-3fca4485b74b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_33383/3959434342.py:5: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  latex_table = table_df.to_latex(index=False)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "table_df = pd.DataFrame(table_overall)\n",
    "table_df.columns = dataset_names\n",
    "table_df.index = [m[0] for m in models]\n",
    "latex_table = table_df.to_latex(index=False)\n",
    "# To save the LaTeX table to a file:\n",
    "with open('table_knn.tex', 'w') as f:\n",
    "    f.write(latex_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "812f8daf-10b4-4a1b-8515-6c18c9902535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's the modified LaTeX table with reduced decimal places and added row labels:\n",
      "\n",
      "\\begin{tabular}{lrrrrrr}\n",
      "\\toprule\n",
      "Classifier & Wine & Breast Cancer & Digits & Diabetes & Covertype & Abalone \\\\\n",
      "\\midrule\n",
      "KNeighborsClassifier & 0.750 & 0.667 & 0.667 & 0.667 & 0.667 & 0.611 \\\\\n",
      "HybridKNNClassifier & 1.000 & 1.000 & 0.944 & 1.000 & 0.972 & 0.917 \\\\\n",
      "MultiLevelAbstractionKNN & 0.944 & 0.889 & 0.917 & 0.972 & 0.944 & 1.000 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n"
     ]
    }
   ],
   "source": [
    "table_result = gen(latex_table + '\\n given this latex table, reduce the number of digits after the decimal to 3, and add row labels according to: ' + str([m[0] for m in models]))\n",
    "print(table_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4b617cb2-c855-49be-a96a-ff3458480295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate_model(LogisticRegression(), \"20 Newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ddcc720-964c-4a48-b1ef-598753230ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "result = evaluate_model(KNeighborsClassifier(), \"Wine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4cc8bdef-4657-46f6-a4f6-9e52be9d8d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_n = evaluate_model(KNeighborsClassifier(), \"20 Newsgroups\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4f5c3088-25e4-4174-a0a0-fe4cdccb121c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9fe16f73-1947-4b78-9db1-93383a4f2818",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [61], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result_n[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not str"
     ]
    }
   ],
   "source": [
    "result_n['accuracy']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed83cdbd-1a20-4ef1-b7bb-8e5d810f8df7",
   "metadata": {},
   "source": [
    "# Essential MetaOmni Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96646a10-7ffc-4296-9de8-b122d4cdca25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a31117f-bd35-4ea5-a957-abff96eb4563",
   "metadata": {},
   "source": [
    "# Initial experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b54ca0d3-d7c2-42ee-89d3-f5d72a2be2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = 'K-nearest-neighbors'\n",
    "class_name_prompt = f\"\"\"Write a succinct pythonic class name for a model with name {model}, putting the name between the XML tags <name>Insert Class Name of Model Here</name>\"\"\"\n",
    "class_name = extract_name(gen(class_name_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9f1ade80-bf4a-4f1b-a0a2-6bebddb13eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name_prompt = f\"\"\"Write a succinct pythonic file name for a model with name {model}, putting the file name between the XML tags <name>Insert Class Name of File Here</name>\"\"\"\n",
    "file_name = extract_name(gen(file_name_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "02982850-e93e-41b7-9f4d-08053ba17960",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_string = f\"import {file_name.split('.py')[0]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ef3f9e31-927f-40b2-b77a-42e8cffbf267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import knn_model'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76973d40-3aa0-4c47-b81d-f35675123c5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First code snippet saved to logistic_regression.py\n",
      "Added 'import knn_model' to metaomni/__init__.py\n"
     ]
    }
   ],
   "source": [
    "model = 'logistic regression'\n",
    "\n",
    "class_name_prompt = f\"\"\"Write a succinct pythonic class name for a model with name {model}, putting the name between the XML tags <name>Insert Class Name of Model Here</name>\"\"\"\n",
    "class_name = extract_name(gen(class_name_prompt))\n",
    "\n",
    "filename_prompt = f\"\"\"Write a succinct pythonic file name for a model with name {model}, putting the file name between the XML tags <name>Insert Class Name of File Here</name>\"\"\"\n",
    "filename = extract_name(gen(filename_prompt))\n",
    "\n",
    "import_string = f\"import {filename.split('.py')[0]}\"\n",
    "\n",
    "prompt = f\"\"\"Write a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "implementation = gen(prompt)\n",
    "\n",
    "snippets = extract_code_snippets(implementation)\n",
    "save_first_snippet(snippets, 'metaomni/' + filename)\n",
    "add_import_to_init('metaomni/__init__.py', import_string)\n",
    "\n",
    "EXECUTION_STRINGS = f\"\"\"importlib.reload(metaomni)\n",
    "ml_model = metaomni.{filename.split('.py')[0]}.{class_name}()\n",
    "ml_model.fit(x_train, y_train)\n",
    "preds = ml_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(accuracy)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6f53a62b-c31e-4318-b2e6-74aab393e799",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "5bee17bc-8a9e-4883-bf63-7eedc1833fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0222f0a-e5c4-4fa7-974c-1022bf4ba7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# file_string = open(f'metaomni/{filename}', 'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0360cea-70c9-401c-99ba-c6767570200f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0d2a61-86bd-468a-b254-11d6b7ece126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2a83b82-0e6f-4c37-a131-d2694f8b4089",
   "metadata": {},
   "source": [
    "# Standard KNN, Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4484db98-6fbd-4d1d-945b-219e2dfcaee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's a simple K-nearest neighbors classifier implemented in the style of scikit-learn, with a KNN class that has fit() and predict() methods:\n",
      "\n",
      "```python\n",
      "import numpy as np\n",
      "from collections import Counter\n",
      "\n",
      "class KNN:\n",
      "    def __init__(self, k=10):\n",
      "        self.k = k\n",
      "\n",
      "    def fit(self, X_train, y_train):\n",
      "        self.X_train = X_train\n",
      "        self.y_train = y_train\n",
      "\n",
      "    def predict(self, X_test):\n",
      "        predictions = [self._predict(x) for x in X_test]\n",
      "        return np.array(predictions)\n",
      "\n",
      "    def _predict(self, x):\n",
      "        # Compute distances between x and all examples in the training set\n",
      "        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\n",
      "        \n",
      "        # Sort by distance and return indices of the first k neighbors\n",
      "        k_indices = np.argsort(distances)[:self.k]\n",
      "        \n",
      "        # Extract the labels of the k nearest neighbor training samples\n",
      "        k_nearest_labels = [self.y_train[i] for i in k_indices]\n",
      "        \n",
      "        # Return the most common class label\n",
      "        most_common = Counter(k_nearest_labels).most_common(1)\n",
      "        return most_common[0][0]\n",
      "```\n",
      "\n",
      "This implementation includes the following features:\n",
      "\n",
      "1. The `KNN` class is initialized with a parameter `k`, which defaults to 10.\n",
      "\n",
      "2. The `fit` method simply stores the training data and labels.\n",
      "\n",
      "3. The `predict` method takes a set of test samples and returns an array of predictions by calling the `_predict` method for each sample.\n",
      "\n",
      "4. The `_predict` method does the following for a single test sample:\n",
      "   - Calculates the Euclidean distance between the test sample and all training samples.\n",
      "   - Sorts the distances and selects the k nearest neighbors.\n",
      "   - Extracts the labels of these k nearest neighbors.\n",
      "   - Returns the most common label among these neighbors as the prediction.\n",
      "\n",
      "You can use this classifier as follows:\n",
      "\n",
      "```python\n",
      "# Create and train the model\n",
      "knn = KNN(k=3)\n",
      "knn.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions\n",
      "predictions = knn.predict(X_test)\n",
      "```\n",
      "\n",
      "Note that this is a basic implementation and doesn't include some of the optimizations that scikit-learn's KNeighborsClassifier has, such as using more efficient data structures for nearest neighbor search. However, it follows a similar interface and should work for small to medium-sized datasets.\n"
     ]
    }
   ],
   "source": [
    "print(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84e1b9fa-5e28-41fa-8df7-a41e0f224757",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3860ba7b-79df-4cdd-9545-fb6442344d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_list = extract_code_snippets(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "351936fe-2262-49dd-bedf-07c6255c16b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'import numpy as np\\nfrom collections import Counter\\n\\nclass KNN:\\n    def __init__(self, k=10):\\n        self.k = k\\n\\n    def fit(self, X_train, y_train):\\n        self.X_train = X_train\\n        self.y_train = y_train\\n\\n    def predict(self, X_test):\\n        predictions = [self._predict(x) for x in X_test]\\n        return np.array(predictions)\\n\\n    def _predict(self, x):\\n        # Compute distances between x and all examples in the training set\\n        distances = [np.sqrt(np.sum((x - x_train)**2)) for x_train in self.X_train]\\n        \\n        # Sort by distance and return indices of the first k neighbors\\n        k_indices = np.argsort(distances)[:self.k]\\n        \\n        # Extract the labels of the k nearest neighbor training samples\\n        k_nearest_labels = [self.y_train[i] for i in k_indices]\\n        \\n        # Return the most common class label\\n        most_common = Counter(k_nearest_labels).most_common(1)\\n        return most_common[0][0]'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47494d48-e7dc-4973-98f6-2d27c87eae5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee45331-6d7a-4586-81da-578ca76229bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_first_snippet(knn, 'AlgoGen/knn.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "132bb1de-fb69-4111-a5fa-b6bc395f218f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f268b11a-4645-431f-9580-a85c5708d241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import metaomni as mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93f84158-040a-4a89-a3c9-c862ad0cb5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import metaomni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98cef28b-92fe-43e3-bb26-efe6ba2456f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'metaomni' from '/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/__init__.py'>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "edf89cde-c11b-4895-9e0a-346aef2bda09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " 'knn']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(metaomni)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c2e5ba6e-32b3-4398-b701-a0f2dfbbc6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2956a82d-d09a-4e78-a90d-a29f438fc42b",
   "metadata": {},
   "source": [
    "# Load and Execute MetaOmni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "94f79ad8-99e6-44c8-81a8-ccf8fc51f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(metaomni)\n",
    "KNN = metaomni.knn.KNN()\n",
    "KNN.fit(x_train, y_train)\n",
    "preds = KNN.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f68611d7-a8cc-4140-835f-7d9266891560",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = accuracy_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d256d5f8-0d06-4d2f-b3ac-5fcc0f1644ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ec64d98d-4118-47bf-b52e-48e3f8a4165d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "d488dac7-f3cc-4ac5-a1b0-ee2a6997ae4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove('metaomni/logistic_regression.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b28d82f-3e34-4f3f-88c5-9e1eaae31153",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'logistic regression'\n",
    "\n",
    "def execute(filename, class_name, model, count=1):\n",
    "    if count > 2:\n",
    "        try:\n",
    "            os.remove(filename)\n",
    "            return\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    EXECUTION_STRINGS = f\"\"\"importlib.reload(metaomni)\n",
    "ml_model = metaomni.{filename.split('.py')[0]}.{class_name}()\n",
    "ml_model.fit(x_train, y_train)\n",
    "preds = ml_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(class_name, accuracy)\"\"\"\n",
    "    \n",
    "    try:\n",
    "        exec(EXECUTION_STRINGS)\n",
    "    except Exception as e:\n",
    "        error_message = traceback.format_exc()\n",
    "        print(\"Hit error: \", error_message)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Existing code:\n",
    "        {open(f'metaomni/{filename}', 'r').read()}\n",
    "    \n",
    "        Error message on original execution:\n",
    "        {e}\n",
    "    \n",
    "        Full traceback:\n",
    "        {error_message}\n",
    "    \n",
    "        Given the original code and this error, rewrite a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "        implementation = gen(prompt)\n",
    "        \n",
    "        snippets = extract_code_snippets(implementation)\n",
    "        save_first_snippet(snippets, 'metaomni/' + filename)\n",
    "        execute(filename, class_name, model, count+1)\n",
    "\n",
    "def genML(model):\n",
    "    class_name_prompt = f\"\"\"Write a succinct pythonic class name for a model with name {model}, putting the name between the XML tags <name>Insert Class Name of Model Here</name>\"\"\"\n",
    "    class_name = extract_name(gen(class_name_prompt))\n",
    "    \n",
    "    filename_prompt = f\"\"\"Write a succinct pythonic file name for a model with name {model}, putting the file name between the XML tags <name>Insert Class Name of File Here</name>\"\"\"\n",
    "    filename = extract_name(gen(filename_prompt))\n",
    "    \n",
    "    import_string = f\"import {filename.split('.py')[0]}\"\n",
    "    \n",
    "    prompt = f\"\"\"Write a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "    implementation = gen(prompt)\n",
    "    \n",
    "    snippets = extract_code_snippets(implementation)\n",
    "    save_first_snippet(snippets, 'metaomni/' + filename)\n",
    "    add_import_to_init('metaomni/__init__.py', import_string)\n",
    "    execute(filename, class_name, model, count=1)\n",
    "    return (filename, class_name)\n",
    "\n",
    "def parallel_genML(prompt_list):\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(genML, prompt_list), total=len(prompt_list)))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84d3093-443a-43e4-89e2-922be40a4006",
   "metadata": {},
   "source": [
    "# Generate New Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b47071a2-f220-4e5e-a711-963737f29b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ideas = \"\"\"Adaptive Compression KNN: Instead of using raw feature spaces, dynamically compress the data based on local density. In sparse regions, use less compression to maintain detail, while in dense regions, apply more compression to reduce noise. This approach balances simplicity and complexity adaptively.\n",
    "Bias-Variance Optimized KNN: Implement an ensemble of KNN classifiers with different k values. Use a meta-learner to dynamically weight their contributions based on estimated bias and variance for each input, optimizing the bias-variance trade-off for each prediction.\n",
    "Multi-level Abstraction KNN: Create a hierarchical KNN that operates at multiple levels of abstraction. Start with high-level features for initial neighborhood selection, then progressively refine using more detailed features. This could capture both coarse and fine-grained structures in the data.\n",
    "Compression-based Similarity KNN: Instead of using traditional distance metrics, define similarity based on the compressibility of the concatenated feature vectors of two instances. This could capture complex, non-linear relationships between features.\n",
    "Directional KNN: Introduce directionality into the KNN algorithm by giving more weight to neighbors that are \"in front of\" the query point in the direction of the decision boundary. This could improve performance in datasets with complex decision boundaries.\n",
    "Continuous-Discrete Hybrid KNN: Develop a KNN variant that seamlessly handles both continuous and discrete features. Use appropriate distance metrics for each type and combine them using a learned weighting scheme, allowing for better handling of mixed data types.\n",
    "Fractal Dimension KNN: Estimate the local fractal dimension of the feature space around each query point. Use this to adaptively set k or to weight neighbors, potentially capturing complex local structures in the data.\n",
    "Similarity-Dissimilarity Balanced KNN: Instead of just finding similar neighbors, also consider dissimilar points. Make decisions based on a balance of both similar and dissimilar instances, potentially improving robustness and decision boundary placement.\n",
    "Entropy-Guided KNN: Use local entropy estimates to guide the KNN algorithm. In high-entropy (more random) regions, increase k to reduce noise influence. In low-entropy (more structured) regions, decrease k to capture fine-grained patterns.\n",
    "Interaction-Aware KNN: Develop a KNN variant that explicitly models feature interactions. Use techniques like feature crossing or learned feature interactions to create a richer representation space for finding neighbors, potentially capturing complex patterns that individual features miss.\"\"\".split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d90fd0f-fde5-47c5-8dee-b4eac7a3aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear Regression\n",
    "# Logistic Regression\n",
    "# Perceptron\n",
    "# K-Nearest Neighbors\n",
    "# Naive Bayes\n",
    "# Decision Trees\n",
    "# Support Vector Machines\n",
    "# K-Means Clustering\n",
    "# Random Forests\n",
    "# AdaBoost\n",
    "# Gradient Boosting Machines\n",
    "# XGBoost\n",
    "# Principal Component Analysis (PCA)\n",
    "# Independent Component Analysis (ICA)\n",
    "# Gaussian Mixture Models\n",
    "# One-Class SVM\n",
    "# Isolation Forest\n",
    "# Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f5411a8-5be4-43c7-8ff2-2ee4c825d522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More principles\n",
    "\n",
    "# Abstraction: Representing complex data or processes at different levels of detail or generality.\n",
    "# Compression: Reducing the dimensionality or complexity of data while preserving essential information.\n",
    "# Sparsity: Utilizing or encouraging solutions with few non-zero elements.\n",
    "# Smoothing: Reducing noise or irregularities in data or model behavior.\n",
    "# Discretization: Converting continuous data or processes into discrete counterparts.\n",
    "# Continuization: Making discrete data or processes continuous for easier manipulation.\n",
    "# Similarity and Distance: Measuring how alike or different entities are in various spaces.\n",
    "# Hierarchy: Organizing information or computations in levels of increasing complexity or abstraction.\n",
    "# Composition: Combining simpler elements to create more complex structures or behaviors.\n",
    "# Decomposition: Breaking complex problems or data into simpler, manageable parts.\n",
    "# Iteration: Repeatedly applying processes to refine results or converge on solutions.\n",
    "# Randomization: Introducing controlled randomness to improve robustness or exploration.\n",
    "# Regularization: Constraining models to prevent overfitting and improve generalization.\n",
    "# Adaptation: Modifying behavior based on feedback or changing conditions.\n",
    "# Ensemble: Combining multiple models or perspectives to improve overall performance.\n",
    "# Transfer: Applying knowledge from one domain or task to another.\n",
    "# Attention: Focusing computational resources on the most relevant parts of the input.\n",
    "# Memory: Storing and recalling information over time to inform current decisions.\n",
    "# Generalization: Extracting patterns that apply beyond the specific instances seen during training.\n",
    "# Discretization: Converting continuous data or processes into discrete counterparts.\n",
    "# Inference: Drawing conclusions or making predictions based on incomplete information.\n",
    "# Representation: Finding effective ways to encode information for specific tasks.\n",
    "# Optimization: Finding the best solution within constraints.\n",
    "# Factorization: Breaking down complex structures into simpler, constituent parts.\n",
    "# Augmentation: Expanding available data or features to improve learning or robustness.\n",
    "# Adversarial Thinking: Improving models by considering potential oppositions or weaknesses.\n",
    "# Bootstrapping: Using the model's own predictions to improve itself or to generate new data.\n",
    "# Marginalization: Focusing on overall patterns by averaging out less important details.\n",
    "# Disentanglement: Separating mixed or confounded factors in data or representations.\n",
    "# Locality: Exploiting the idea that nearby points in input space should have similar outputs.\n",
    "\n",
    "# Abstraction: Representing complex ideas or data in a simplified form.\n",
    "# Compression: Reducing the size or dimensionality of data while preserving essential information.\n",
    "# Sparsity: Utilizing or encouraging solutions with few non-zero elements.\n",
    "# Smoothing: Reducing noise or irregularities in data or model behavior.\n",
    "# Discretization: Converting continuous data or processes into distinct categories or steps.\n",
    "# Continuization: Making discrete data or processes continuous for easier manipulation.\n",
    "# Similarity and Distance: Quantifying how alike or different entities are in various spaces.\n",
    "# Hierarchy: Organizing information or computations in levels of increasing complexity or abstraction.\n",
    "# Composition: Combining simpler elements to create more complex structures or behaviors.\n",
    "# Decomposition: Breaking complex problems or data into simpler, manageable parts.\n",
    "# Iteration: Repeatedly applying processes to refine results or converge on solutions.\n",
    "# Randomization: Introducing controlled randomness to improve robustness or exploration.\n",
    "# Regularization: Constraining models to prevent overfitting and improve generalization.\n",
    "# Adaptation: Modifying behavior based on feedback or changing conditions.\n",
    "# Ensemble: Combining multiple models or perspectives to improve overall performance.\n",
    "# Transfer: Applying knowledge from one domain or task to another.\n",
    "# Attention: Focusing computational resources on the most relevant parts of the input.\n",
    "# Memory: Storing and recalling information over time to inform current decisions.\n",
    "# Generalization: Extracting patterns that apply beyond the specific instances seen during training.\n",
    "# Inference: Drawing conclusions or making predictions based on incomplete information.\n",
    "# Representation: Finding effective ways to encode information for specific tasks.\n",
    "# Optimization: Finding the best solution within given constraints.\n",
    "# Factorization: Breaking down complex structures into simpler, constituent parts.\n",
    "# Augmentation: Expanding available data or features to improve learning or robustness.\n",
    "# Adversarial Thinking: Improving models by considering potential oppositions or weaknesses.\n",
    "# Bootstrapping: Using the model's own predictions to improve itself or to generate new data.\n",
    "# Marginalization: Focusing on overall patterns by averaging out less important details.\n",
    "# Disentanglement: Separating mixed or confounded factors in data or representations.\n",
    "# Locality: Exploiting the idea that nearby points in input space should have similar outputs.\n",
    "# Dimensionality: Considering the number of features or parameters in relation to the amount of data.\n",
    "# Invariance: Maintaining consistent outputs despite certain transformations of the input.\n",
    "# Equivariance: Transforming outputs in predictable ways when inputs are transformed.\n",
    "# Causality: Identifying and leveraging cause-effect relationships in data.\n",
    "# Uncertainty: Quantifying and propagating the degree of confidence in predictions or estimates.\n",
    "# Bias-Variance Tradeoff: Balancing the model's ability to fit training data versus its ability to generalize.\n",
    "# Interpolation: Estimating values between known data points.\n",
    "# Extrapolation: Extending predictions beyond the range of known data.\n",
    "# Kernelization: Implicitly mapping data to higher-dimensional spaces for easier separation.\n",
    "# Boosting: Iteratively improving weak learners to create a strong learner.\n",
    "# Bagging: Reducing variance by training models on random subsets of the data.\n",
    "# Stacking: Layering multiple models to capture different aspects of the data.\n",
    "# Incrementalism: Updating models or knowledge gradually as new information becomes available.\n",
    "# Batch Processing: Processing data in groups rather than individually or continuously.\n",
    "# Active Sampling: Selectively choosing the most informative data points for labeling or analysis.\n",
    "# Semi-Supervision: Leveraging both labeled and unlabeled data for training.\n",
    "# Self-Supervision: Creating supervised tasks from unlabeled data.\n",
    "# Multi-Task Integration: Improving generalization by learning multiple related tasks simultaneously.\n",
    "# Curriculum Design: Presenting training data in a meaningful order to improve learning.\n",
    "# Few-Shot Adaptation: Generalizing from very few examples of new classes or tasks.\n",
    "# Zero-Shot Inference: Recognizing or generating examples of classes not seen during training.\n",
    "# Continual Accumulation: Accumulating knowledge over time without catastrophic forgetting.\n",
    "# Meta-Learning: Learning how to learn, or improving the learning process itself.\n",
    "# Embedding: Mapping discrete entities to continuous vector spaces.\n",
    "# Quantization: Discretizing continuous values for efficiency or generalization.\n",
    "# Pruning: Removing unnecessary components of a model to improve efficiency.\n",
    "# Distillation: Transferring knowledge from complex models to simpler ones.\n",
    "# Flow: Ensuring effective propagation of information through complex systems.\n",
    "# Normalization: Adjusting and scaling features or activations to improve stability and performance.\n",
    "# Residual Learning: Learning differences or corrections rather than absolute mappings.\n",
    "# Gating: Controlling information flow in neural networks or decision processes.\n",
    "# Contrastive Analysis: Learning by comparing similar and dissimilar examples.\n",
    "# Generation: Creating new examples that resemble the training data.\n",
    "# Discrimination: Focusing on boundaries between classes rather than full data distribution.\n",
    "# Robustness: Maintaining performance under varying or adverse conditions.\n",
    "# Multimodal Fusion: Integrating information from multiple types of data or sensors.\n",
    "# Anomaly Detection: Identifying patterns that deviate significantly from the norm.\n",
    "# Reinforcement: Learning through interaction with an environment.\n",
    "# Exploration vs. Exploitation: Balancing the need to gather new information with the use of existing knowledge.\n",
    "# Credit Assignment: Determining which actions or decisions led to particular outcomes.\n",
    "# Temporal Difference: Updating estimates based on other estimates in sequential decision problems.\n",
    "# Imitation: Learning behavior by mimicking demonstrations or examples.\n",
    "# Inverse Problem Solving: Inferring causes or inputs from observed effects or outputs.\n",
    "# Domain Adaptation: Adjusting models to perform well on related but distinct data distributions.\n",
    "# Conditional Manipulation: Treat aspects of the input differently.\n",
    "# Information Bottleneck: Compressing inputs while preserving task-relevant information.\n",
    "# Mutual Information: Measuring the mutual dependence between variables.\n",
    "# Counterfactual Reasoning: Considering hypothetical scenarios to improve decision-making.\n",
    "# Intervention: Incorporating the effects of actions or changes in causal models.\n",
    "# Distribution Shift Handling: Adapting to changes in data distribution between training and deployment.\n",
    "# Interpretability: Making model decisions understandable to humans.\n",
    "# Saliency: Identifying the most relevant features or inputs for a particular output or decision.\n",
    "# Architecture Search: Automatically discovering effective model structures.\n",
    "# Hyperparameter Tuning: Efficiently optimizing model parameters that are not learned during training.\n",
    "# Mixup: Combining training examples to regularize the model and increase robustness.\n",
    "# Curriculum Complexity: Gradually increasing the difficulty of tasks or examples during training.\n",
    "# Accumulation: Aggregating information or updates over time to improve stability or performance.\n",
    "# Distributed Learning: Collaboratively learning from distributed data sources or models.\n",
    "# Symbolic-Subsymbolic Integration: Combining rule-based systems with neural networks.\n",
    "# Graph Representation: Modeling relationships and interactions between entities as graphs.\n",
    "# Amortization: Using learned models to speed up repeated computations or inferences.\n",
    "# Energy Minimization: Framing learning and inference as minimizing an energy function.\n",
    "# Denoising: Removing noise or unwanted variations from data or representations.\n",
    "# Latent Space Manipulation: Operating on compressed or abstract representations of data.\n",
    "# Prototype Learning: Learning representative examples or templates for classes or concepts.\n",
    "# Modularity: Organizing systems into independent, interchangeable components.\n",
    "# Emergence: Observing complex behaviors arising from simple rules or interactions.\n",
    "# Self-Organization: Allowing systems to spontaneously form structured patterns or behaviors.\n",
    "# Homeostasis: Maintaining stable internal states despite external fluctuations.\n",
    "# Synchronization: Coordinating the behavior of multiple components or agents.\n",
    "# Oscillation: Utilizing or managing cyclic patterns in data or model behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6149bf6c-8109-4141-8da2-37541969dd4b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gen' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [6], line 27\u001b[0m\n\u001b[1;32m     13\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mRandom Forests\u001b[39m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;124mNeural Network Classifier\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124mBagged Decision Trees\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;124mQuadratic Discriminant Analysis\u001b[39m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;124mLinear Discriminant Analysis\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[0;32m---> 27\u001b[0m     ideas_raw \u001b[38;5;241m=\u001b[39m gen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mPrinciples of Machine Learning:\u001b[39m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;124mSimplicity vs. complexity\u001b[39m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124mBias - Variance Decomposition\u001b[39m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124mAbstraction - level of abstraction at which more or less structure, or different types of structure are present\u001b[39m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124mFramed as Compression\u001b[39m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;124mDegree of Compression\u001b[39m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;124mDirectionality\u001b[39m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;124mDiscrete vs. Continuous\u001b[39m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;124mAbstraction - fine vs. coarse grain structure\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;124mSimilarity, say, with a feature or set of features\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;124mRandomness, degree to which there is structure, compressibility of data\u001b[39m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;124mDimensionality - Interactions between features vs. single feature structure\u001b[39m\n\u001b[1;32m     39\u001b[0m \n\u001b[1;32m     40\u001b[0m \u001b[38;5;124mInspired by these principles, come up with 10 very creative ideas for how to vary the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mm\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m classifier for better performance.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m)\n\u001b[1;32m     41\u001b[0m     ideas_list \u001b[38;5;241m=\u001b[39m [i\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m ideas_raw\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(i) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m i[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39misnumeric()]\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtxt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gen' is not defined"
     ]
    }
   ],
   "source": [
    "principles = \"\"\"Simplicity vs. complexity\n",
    "Bias - Variance Decomposition\n",
    "Abstraction - level of abstraction at which more or less structure, or different types of structure are present\n",
    "Framed as Compression\n",
    "Degree of Compression\n",
    "Directionality\n",
    "Discrete vs. Continuous\n",
    "Abstraction - fine vs. coarse grain structure\n",
    "Similarity, say, with a feature or set of features\n",
    "Randomness, degree to which there is structure, compressibility of data\n",
    "Dimensionality - Interactions between features vs. single feature structure\"\"\".split('\\n')\n",
    "\n",
    "models = \"\"\"Random Forests\n",
    "Neural Network Classifier\n",
    "Bagged Decision Trees\n",
    "Decision Trees for Classificaiton\n",
    "K-Nearest Neighbors\n",
    "Perceptron Classifier\n",
    "Naive Bayes\n",
    "Logistic Regression\n",
    "Support Vector Machine\n",
    "Gradient Boosting Machine\n",
    "Quadratic Discriminant Analysis\n",
    "Linear Discriminant Analysis\"\"\".split('\\n')\n",
    "\n",
    "for m in models[1:]:\n",
    "    ideas_raw = gen(f\"\"\"Principles of Machine Learning:\n",
    "    Simplicity vs. complexity\n",
    "    Bias - Variance Decomposition\n",
    "    Abstraction - level of abstraction at which more or less structure, or different types of structure are present\n",
    "    Framed as Compression\n",
    "    Degree of Compression\n",
    "    Directionality\n",
    "    Discrete vs. Continuous\n",
    "    Abstraction - fine vs. coarse grain structure\n",
    "    Similarity, say, with a feature or set of features\n",
    "    Randomness, degree to which there is structure, compressibility of data\n",
    "    Dimensionality - Interactions between features vs. single feature structure\n",
    "    \n",
    "    Inspired by these principles, come up with 10 very creative ideas for how to vary the {m} classifier for better performance.\"\"\")\n",
    "    ideas_list = [i.split('. ')[1] for i in ideas_raw.split('\\n') if len(i) > 0 and i[0].isnumeric()]\n",
    "    with open(m + 'txt', 'w') as f:\n",
    "        for line in ideas_list:\n",
    "            f.write(f\"{line}\\n\")\n",
    "    parallel_genML(ideas_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8c9ea4a-0283-40b1-9327-2f11c7eb41cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adaptive Abstraction Forests: Dynamically adjust the level of abstraction for each tree based on the data complexity',\n",
       " 'Compression-Guided Pruning: Instead of traditional pruning methods, use data compression techniques to determine which branches to prune',\n",
       " 'Bias-Variance Optimized Forests: Dynamically adjust the number and depth of trees based on real-time estimates of bias and variance',\n",
       " 'Dimensionality-Aware Splitting: Incorporate feature interaction information into the splitting criteria',\n",
       " 'Similarity-Clustered Forests: Group similar data points and train separate \"sub-forests\" on each cluster',\n",
       " 'Continuous-Discrete Hybrid Forests: Develop trees that can handle both continuous and discrete data natively, using a mix of traditional splits and fuzzy logic-based splits to better capture the underlying data structure.',\n",
       " 'Directionality-Sensitive Trees: Incorporate directional information into the tree structure, allowing splits that are sensitive to the \"flow\" or gradient of the data in feature space.',\n",
       " 'Randomness-Adaptive Sampling: Adjust the random sampling process based on the estimated compressibility of different data regions',\n",
       " 'Multi-Scale Random Forests: Train trees at different scales of data abstraction simultaneously',\n",
       " 'Complexity-Guided Ensemble: Instead of giving equal weight to all trees, weight them based on their individual complexity (measured by metrics like minimum description length)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "80624bca-aba5-4344-b99b-aa695f366b9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Here are 10 creative ideas for varying the Random Forests classifier, inspired by the principles you've mentioned:\n",
      "\n",
      "1. Adaptive Abstraction Forests: Dynamically adjust the level of abstraction for each tree based on the data complexity. Use fine-grained splits for high-information regions and coarse-grained splits for low-information areas.\n",
      "\n",
      "2. Compression-Guided Pruning: Instead of traditional pruning methods, use data compression techniques to determine which branches to prune. Branches that contribute less to overall data compression are removed.\n",
      "\n",
      "3. Bias-Variance Optimized Forests: Dynamically adjust the number and depth of trees based on real-time estimates of bias and variance. This could involve growing or pruning trees during training to find the optimal bias-variance trade-off.\n",
      "\n",
      "4. Dimensionality-Aware Splitting: Incorporate feature interaction information into the splitting criteria. For high-dimensional data, prioritize splits that capture complex feature interactions.\n",
      "\n",
      "5. Similarity-Clustered Forests: Group similar data points and train separate \"sub-forests\" on each cluster. Combine predictions using a meta-learner that considers both individual tree outputs and cluster membership.\n",
      "\n",
      "6. Continuous-Discrete Hybrid Forests: Develop trees that can handle both continuous and discrete data natively, using a mix of traditional splits and fuzzy logic-based splits to better capture the underlying data structure.\n",
      "\n",
      "7. Directionality-Sensitive Trees: Incorporate directional information into the tree structure, allowing splits that are sensitive to the \"flow\" or gradient of the data in feature space.\n",
      "\n",
      "8. Randomness-Adaptive Sampling: Adjust the random sampling process based on the estimated compressibility of different data regions. Sample more heavily from areas with higher entropy or less apparent structure.\n",
      "\n",
      "9. Multi-Scale Random Forests: Train trees at different scales of data abstraction simultaneously. Combine predictions across scales, giving more weight to the scale that best captures the structure relevant to each prediction.\n",
      "\n",
      "10. Complexity-Guided Ensemble: Instead of giving equal weight to all trees, weight them based on their individual complexity (measured by metrics like minimum description length). This could help balance the trade-off between model simplicity and predictive power.\n",
      "\n",
      "These ideas aim to leverage the principles you've outlined to create more flexible and adaptive Random Forest variants. They would require careful implementation and testing to validate their effectiveness in practice.\n"
     ]
    }
   ],
   "source": [
    "print(ideas_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2a440316-933f-4948-904c-faa169dba342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb961e9c91b94c5ea41dc929c230e2ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First code snippet saved to metaomni/compression_similarity_knn.py\n",
      "Added import compression_similarity_knn to metaomni/__init__.py\n",
      "CompressibilitySimilarityKNN 0.5555555555555556\n",
      "First code snippet saved to metaomni/interaction_aware_knn.py\n",
      "Added import interaction_aware_knn to metaomni/__init__.py\n",
      "InteractionAwareKNN 0.6944444444444444\n",
      "First code snippet saved to metaomni/multilevel_abstraction_knn.py\n",
      "Added import multilevel_abstraction_knn to metaomni/__init__.py\n",
      "MultiLevelAbstractionKNN 0.9722222222222222\n",
      "First code snippet saved to metaomni/adaptive_density_compression_knn.py\n",
      "Added import adaptive_density_compression_knn to metaomni/__init__.py\n",
      "AdaptiveDensityCompressedKNN 0.3888888888888889\n",
      "First code snippet saved to metaomni/fractal_dimension_adaptive_knn.py\n",
      "Added import fractal_dimension_adaptive_knn to metaomni/__init__.py\n",
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/fractal_dimension_adaptive_knn.py\", line 45, in predict\n",
      "    k = max(1, min(int(self.k_max * fd), self.k_max))\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/fractal_dimension_adaptive_knn.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "  log_counts = np.log(counts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First code snippet saved to metaomni/entropy_guided_knn.py\n",
      "Added import entropy_guided_knn to metaomni/__init__.py\n",
      "EntropyGuidedKNN 0.6944444444444444\n",
      "First code snippet saved to metaomni/sim_dissim_balanced_knn.py\n",
      "Added import sim_dissim_balanced_knn to metaomni/__init__.py\n",
      "First code snippet saved to metaomni/directional_knn.py\n",
      "Added import directional_knn to metaomni/__init__.py\n",
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 2, in <module>\n",
      "AttributeError: module 'metaomni' has no attribute 'directional_knn'\n",
      "\n",
      "BalancedSimDissimKNN 0.75\n",
      "First code snippet saved to metaomni/bias_variance_optimized_knn_ensemble.py\n",
      "Added import bias_variance_optimized_knn_ensemble to metaomni/__init__.py\n",
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/bias_variance_optimized_knn_ensemble.py\", line 54, in predict\n",
      "    final_predictions = self.meta_learner.predict(meta_features)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 451, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 432, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 625, in _validate_data\n",
      "    self._check_n_features(X, reset=reset)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 414, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 1 features, but LogisticRegression is expecting 5 features as input.\n",
      "\n",
      "First code snippet saved to metaomni/hybrid_continuous_discrete_knn.py\n",
      "Added import hybrid_continuous_discrete_knn to metaomni/__init__.py\n",
      "HybridKNNClassifier 0.9444444444444444\n",
      "First code snippet saved to metaomni/directional_knn.py\n",
      "DirectionalWeightedKNN 0.6666666666666666\n",
      "First code snippet saved to metaomni/fractal_dimension_adaptive_knn.py\n",
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/fractal_dimension_adaptive_knn.py\", line 45, in predict\n",
      "    counts.append(np.sum(distances <= size))\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/fractal_dimension_adaptive_knn.py\", line 45, in predict\n",
      "    counts.append(np.sum(distances <= size))\n",
      "ValueError: cannot convert float NaN to integer\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/fractal_dimension_adaptive_knn.py:59: RuntimeWarning: divide by zero encountered in log\n",
      "  log_counts = np.log(counts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First code snippet saved to metaomni/bias_variance_optimized_knn_ensemble.py\n",
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/bias_variance_optimized_knn_ensemble.py\", line 54, in predict\n",
      "    weights /= np.sum(weights, axis=1, keepdims=True)  # Normalize weights\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 451, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 432, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 625, in _validate_data\n",
      "    self._check_n_features(X, reset=reset)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 414, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 1 features, but LogisticRegression is expecting 5 features as input.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/4172171202.py\", line 16, in execute\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 4, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/bias_variance_optimized_knn_ensemble.py\", line 54, in predict\n",
      "    weights /= np.sum(weights, axis=1, keepdims=True)  # Normalize weights\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 451, in predict\n",
      "    scores = self.decision_function(X)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py\", line 432, in decision_function\n",
      "    X = self._validate_data(X, accept_sparse=\"csr\", reset=False)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 625, in _validate_data\n",
      "    self._check_n_features(X, reset=reset)\n",
      "  File \"/Users/jeremynixon/miniforge3/lib/python3.10/site-packages/sklearn/base.py\", line 414, in _check_n_features\n",
      "    raise ValueError(\n",
      "ValueError: X has 1 features, but LogisticRegression is expecting 5 features as input.\n",
      "\n",
      "First code snippet saved to metaomni/fractal_dimension_adaptive_knn.py\n",
      "First code snippet saved to metaomni/bias_variance_optimized_knn_ensemble.py\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'bias_variance_optimized_knn_ensemble.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [127], line 16\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(filename, class_name, model, count)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXECUTION_STRINGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:4\u001b[0m\n",
      "File \u001b[0;32m~/Dropbox/python_new/Misc/metaomni/bias_variance_optimized_knn_ensemble.py:54\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (bias \u001b[38;5;241m+\u001b[39m variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)  \u001b[38;5;66;03m# Add small constant to avoid division by zero\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m weights \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Normalize weights\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Apply weights to base predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LogisticRegression is expecting 5 features as input.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [127], line 16\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(filename, class_name, model, count)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 16\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[43mEXECUTION_STRINGS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m<string>:4\u001b[0m\n",
      "File \u001b[0;32m~/Dropbox/python_new/Misc/metaomni/bias_variance_optimized_knn_ensemble.py:54\u001b[0m, in \u001b[0;36mpredict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     53\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m/\u001b[39m (bias \u001b[38;5;241m+\u001b[39m variance \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1e-10\u001b[39m)  \u001b[38;5;66;03m# Add small constant to avoid division by zero\u001b[39;00m\n\u001b[0;32m---> 54\u001b[0m weights \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Normalize weights\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Apply weights to base predictions\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:451\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    450\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 451\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(scores\u001b[38;5;241m.\u001b[39mshape) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/linear_model/_base.py:432\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    430\u001b[0m xp, _ \u001b[38;5;241m=\u001b[39m get_namespace(X)\n\u001b[0;32m--> 432\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    433\u001b[0m scores \u001b[38;5;241m=\u001b[39m safe_sparse_dot(X, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcoef_\u001b[38;5;241m.\u001b[39mT, dense_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintercept_\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:625\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 625\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_n_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/base.py:414\u001b[0m, in \u001b[0;36mBaseEstimator._check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    413\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_features \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_:\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    415\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX has \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mn_features\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features, but \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    416\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis expecting \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_features_in_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m features as input.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    417\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: X has 1 features, but LogisticRegression is expecting 5 features as input.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [130], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m parallel_genML(ideas)\n",
      "Cell \u001b[0;32mIn [127], line 58\u001b[0m, in \u001b[0;36mparallel_genML\u001b[0;34m(prompt_list)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mparallel_genML\u001b[39m(prompt_list):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m concurrent\u001b[38;5;241m.\u001b[39mfutures\u001b[38;5;241m.\u001b[39mThreadPoolExecutor() \u001b[38;5;28;01mas\u001b[39;00m executor:\n\u001b[0;32m---> 58\u001b[0m         \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenML\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt_list\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tqdm/notebook.py:254\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    253\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 254\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    255\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    256\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    257\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:621\u001b[0m, in \u001b[0;36mExecutor.map.<locals>.result_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fs:\n\u001b[1;32m    619\u001b[0m     \u001b[38;5;66;03m# Careful not to keep a reference to the popped future\u001b[39;00m\n\u001b[1;32m    620\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 621\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    623\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m _result_or_cancel(fs\u001b[38;5;241m.\u001b[39mpop(), end_time \u001b[38;5;241m-\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic())\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:319\u001b[0m, in \u001b[0;36m_result_or_cancel\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 319\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    321\u001b[0m         fut\u001b[38;5;241m.\u001b[39mcancel()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:458\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 458\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/_base.py:403\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    404\u001b[0m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    405\u001b[0m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[1;32m    406\u001b[0m         \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/concurrent/futures/thread.py:58\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 58\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "Cell \u001b[0;32mIn [127], line 53\u001b[0m, in \u001b[0;36mgenML\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     51\u001b[0m save_first_snippet(snippets, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetaomni/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[1;32m     52\u001b[0m add_import_to_init(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetaomni/__init__.py\u001b[39m\u001b[38;5;124m'\u001b[39m, import_string)\n\u001b[0;32m---> 53\u001b[0m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (filename, class_name)\n",
      "Cell \u001b[0;32mIn [127], line 36\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(filename, class_name, model, count)\u001b[0m\n\u001b[1;32m     34\u001b[0m snippets \u001b[38;5;241m=\u001b[39m extract_code_snippets(implementation)\n\u001b[1;32m     35\u001b[0m save_first_snippet(snippets, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetaomni/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [127], line 36\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(filename, class_name, model, count)\u001b[0m\n\u001b[1;32m     34\u001b[0m snippets \u001b[38;5;241m=\u001b[39m extract_code_snippets(implementation)\n\u001b[1;32m     35\u001b[0m save_first_snippet(snippets, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetaomni/\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m filename)\n\u001b[0;32m---> 36\u001b[0m \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [127], line 5\u001b[0m, in \u001b[0;36mexecute\u001b[0;34m(filename, class_name, model, count)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(filename, class_name, model, count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m count \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m----> 5\u001b[0m         \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mremove\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     EXECUTION_STRINGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mimportlib.reload(metaomni)\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mml_model = metaomni.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124mml_model.fit(x_train, y_train)\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124mpreds = ml_model.predict(x_test)\u001b[39m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;124maccuracy = accuracy_score(y_test, preds)\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;124mprint(class_name, accuracy)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'bias_variance_optimized_knn_ensemble.py'"
     ]
    }
   ],
   "source": [
    "parallel_genML(ideas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2d7f4005-d116-44a4-aca6-f75b74a76ce2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier 0.9166666666666666\n",
      "KNN 0.6944444444444444\n"
     ]
    }
   ],
   "source": [
    "model = 'decision tree'\n",
    "filename, class_name = genML(model)\n",
    "# execute(filename, class_name, model)\n",
    "\n",
    "model = 'KNN'\n",
    "filename, class_name = ('knn', 'KNN')\n",
    "# filename, class_name = genML(model)\n",
    "execute(filename, class_name, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "a36c668b-02cd-4580-afce-422cc8fee60b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (120,120) (120,4) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [98], line 11\u001b[0m\n\u001b[1;32m      2\u001b[0m class_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSupportVectorMachine\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      4\u001b[0m EXECUTION_STRINGS \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mimportlib.reload(metaomni)\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124mml_model = metaomni.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m()\u001b[39m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;124mml_model.fit(x_train, y_train)\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;124mpreds = ml_model.predict(x_test)\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124maccuracy = accuracy_score(y_test, preds)\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124mprint(class_name, accuracy)\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m exec(EXECUTION_STRINGS)\n",
      "File \u001b[0;32m<string>:3\u001b[0m\n",
      "File \u001b[0;32m~/Dropbox/python_new/Misc/metaomni/svm_model.py:76\u001b[0m, in \u001b[0;36mSupportVectorMachine.fit\u001b[0;34m(self, X_train, y_train)\u001b[0m\n\u001b[1;32m     73\u001b[0m         iterations \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Compute weights\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mw \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malphas\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnewaxis\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (120,120) (120,4) "
     ]
    }
   ],
   "source": [
    "filename = 'svm_model.py'\n",
    "class_name = 'SupportVectorMachine'\n",
    "\n",
    "EXECUTION_STRINGS = f\"\"\"importlib.reload(metaomni)\n",
    "ml_model = metaomni.{filename.split('.py')[0]}.{class_name}()\n",
    "ml_model.fit(x_train, y_train)\n",
    "preds = ml_model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(class_name, accuracy)\"\"\"\n",
    "\n",
    "exec(EXECUTION_STRINGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "57694736-23ad-4c5c-9b45-3b11a67269eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hit error:  Traceback (most recent call last):\n",
      "  File \"/var/folders/nf/0ddppczj5wn6s4m23ymy4y740000gn/T/ipykernel_79920/2765892195.py\", line 4, in <module>\n",
      "    exec(EXECUTION_STRINGS)\n",
      "  File \"<string>\", line 3, in <module>\n",
      "  File \"/Users/jeremynixon/Dropbox/python_new/Misc/metaomni/svm_model.py\", line 76, in fit\n",
      "    iterations = 0\n",
      "ValueError: operands could not be broadcast together with shapes (120,120) (120,4) \n",
      "\n",
      "First code snippet saved to metaomni/svm_model.py\n"
     ]
    }
   ],
   "source": [
    "model = 'support vector machine'\n",
    "\n",
    "try:\n",
    "    exec(EXECUTION_STRINGS)\n",
    "except Exception as e:\n",
    "    error_message = traceback.format_exc()\n",
    "    print(\"Hit error: \", error_message)\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Existing code:\n",
    "    {open(f'metaomni/{filename}', 'r').read()}\n",
    "\n",
    "    Error message on original execution:\n",
    "    {e}\n",
    "\n",
    "    Full traceback:\n",
    "    {error_message}\n",
    "\n",
    "    Given the original code and this error, rewrite a {model} classifier in the style of SciKit learn, with a {class_name} class that implements the methods fit(self, X_train, y_train) and predict(self, X_test)\"\"\"\n",
    "    implementation = gen(prompt)\n",
    "    \n",
    "    snippets = extract_code_snippets(implementation)\n",
    "    save_first_snippet(snippets, 'metaomni/' + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d48e02-bf31-457a-9a49-ac44f312bb9d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa9b8c2d-cffe-4a7c-adf9-05fb5e9bf1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_init_file(directory):\n",
    "    # Get all Python files in the directory\n",
    "    python_files = [f for f in os.listdir(directory) if f.endswith('.py') and f != '__init__.py']\n",
    "    \n",
    "    # Generate import statements\n",
    "    import_statements = []\n",
    "    for file in python_files:\n",
    "        module_name = file[:-3]  # Remove .py extension\n",
    "        \n",
    "        # Check if the module can be imported\n",
    "        spec = importlib.util.spec_from_file_location(module_name, os.path.join(directory, file))\n",
    "        if spec is not None:\n",
    "            import_statements.append(f\"from .{module_name} import *\")\n",
    "    \n",
    "    # Write the __init__.py file\n",
    "    init_path = os.path.join(directory, '__init__.py')\n",
    "    with open(init_path, 'w') as init_file:\n",
    "        init_file.write('\\n'.join(import_statements))\n",
    "    \n",
    "    print(f\"__init__.py file has been generated in {directory}\")\n",
    "# generate_init_file('metaomni')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e066b2f4-83f7-4ac0-8a46-877ed6bfd538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "aknn = mo.MultiLevelAbstractionKNN(abstraction_ratios=[1.0, 1.0, 1.0])\n",
    "aknn.fit(x_train, y_train)\n",
    "preds = aknn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, preds)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff486cd-0929-4042-b088-d6abd53485aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "89b03311-cc97-4422-b666-7f3020d18d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris, load_wine, load_breast_cancer, load_digits, fetch_california_housing, fetch_olivetti_faces\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "from sklearn.base import BaseEstimator\n",
    "from typing import List, Tuple, Dict, Union\n",
    "\n",
    "class BenchmarkSuite:\n",
    "    def __init__(self, test_size: float = 0.2, random_state: int = 42):\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "        self.datasets = self._load_datasets()\n",
    "        self.results = {}\n",
    "\n",
    "    def _load_datasets(self) -> Dict[str, Tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]]:\n",
    "        datasets = {\n",
    "            'Iris': load_iris(return_X_y=True),\n",
    "            'Wine': load_wine(return_X_y=True),\n",
    "            'Breast Cancer': load_breast_cancer(return_X_y=True),\n",
    "            'Digits': load_digits(return_X_y=True),\n",
    "            'California Housing': fetch_california_housing(return_X_y=True),\n",
    "            'Olivetti Faces': fetch_olivetti_faces(return_X_y=True)\n",
    "        }\n",
    "\n",
    "        split_datasets = {}\n",
    "        for name, (X, y) in datasets.items():\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=self.test_size, random_state=self.random_state\n",
    "            )\n",
    "            scaler = StandardScaler()\n",
    "            X_train_scaled = scaler.fit_transform(X_train)\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            split_datasets[name] = (X_train_scaled, X_test_scaled, y_train, y_test)\n",
    "        \n",
    "        return split_datasets\n",
    "\n",
    "    def run_benchmark(self, models: List[BaseEstimator]) -> Dict[str, Dict[str, float]]:\n",
    "        for model in models:\n",
    "            model_name = model.__class__.__name__\n",
    "            self.results[model_name] = {}\n",
    "\n",
    "            for dataset_name, (X_train, X_test, y_train, y_test) in self.datasets.items():\n",
    "                model.fit(X_train, y_train)\n",
    "                y_pred = model.predict(X_test)\n",
    "                \n",
    "                if dataset_name in ['California Housing', 'Olivetti Faces']:\n",
    "                    score = r2_score(y_test, y_pred)\n",
    "                    metric = 'R2 Score'\n",
    "                else:\n",
    "                    score = accuracy_score(y_test, y_pred)\n",
    "                    metric = 'Accuracy'\n",
    "                \n",
    "                self.results[model_name][dataset_name] = {metric: score}\n",
    "\n",
    "        return self.results\n",
    "\n",
    "    def print_results(self):\n",
    "        for model, datasets in self.results.items():\n",
    "            print(f\"\\nResults for {model}:\")\n",
    "            for dataset, scores in datasets.items():\n",
    "                for metric, score in scores.items():\n",
    "                    print(f\"  {dataset} - {metric}: {score:.4f}\")\n",
    "\n",
    "# Example usage:\n",
    "# from sklearn.svm import SVC\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "suite = BenchmarkSuite()\n",
    "models = [mo.MultiLevelAbstractionKNN()]\n",
    "results = suite.run_benchmark(models)\n",
    "suite.print_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9a0f728d-f8ed-4bae-9e59-98bd10e3e655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As a research engineer, I can provide you with 10 professional visualizations commonly used to compare machine learning algorithm performances and visualize classifier performance:\\n\\n1. Receiver Operating Characteristic (ROC) Curve:\\n   - Plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\\n   - Useful for binary classification problems and comparing multiple classifiers.\\n   - The Area Under the Curve (AUC) provides a single scalar value to compare classifiers.\\n\\n2. Precision-Recall Curve:\\n   - Plots Precision against Recall at various threshold settings.\\n   - Particularly useful for imbalanced datasets where ROC curves might be overly optimistic.\\n   - The Area Under the Precision-Recall Curve (AUPRC) can be used as a single metric for comparison.\\n\\n3. Confusion Matrix Heatmap:\\n   - A color-coded matrix showing True Positives, True Negatives, False Positives, and False Negatives.\\n   - Useful for multi-class classification problems.\\n   - Can be normalized to show percentages instead of raw counts.\\n\\n4. Learning Curves:\\n   - Plots training and validation scores against the number of training samples.\\n   - Helps diagnose bias and variance issues in the model.\\n   - Can be used to determine if more data would be beneficial.\\n\\n5. Validation Curve:\\n   - Plots training and validation scores against a specific hyperparameter.\\n   - Useful for tuning individual hyperparameters and understanding their impact on model performance.\\n\\n6. Feature Importance Plot:\\n   - Bar chart or horizontal bar plot showing the importance of each feature in the model.\\n   - Commonly used with tree-based methods (e.g., Random Forests, Gradient Boosting).\\n   - Can help in feature selection and understanding which features contribute most to the model's decisions.\\n\\n7. Lift Chart:\\n   - Shows how much better your model is at predicting compared to a random selection.\\n   - Particularly useful in marketing and customer targeting scenarios.\\n\\n8. Calibration Plot:\\n   - Plots the predicted probabilities against the true probabilities.\\n   - Helps assess whether a classifier is well-calibrated (i.e., its predicted probabilities match observed probabilities).\\n\\n9. Silhouette Plot:\\n   - Used for clustering algorithms to visualize the quality of clusters.\\n   - Shows how similar an object is to its own cluster compared to other clusters.\\n\\n10. t-SNE or UMAP Plot:\\n    - Dimensionality reduction techniques that can visualize high-dimensional data in 2D or 3D.\\n    - Useful for visualizing how well different algorithms separate classes in the feature space.\\n    - Can be color-coded by true labels or predicted labels to show classification performance.\\n\\nThese visualizations provide different perspectives on model performance and can be used in combination to gain a comprehensive understanding of how different algorithms compare and how well individual classifiers perform. The choice of visualization depends on the specific problem, the type of algorithm, and the aspects of performance you want to highlight.\""
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen(\"What are 10 professional visualizations to compare machine learning algorithm performaces to each other, and generally to visualize the performance of classifiers?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "43953e80-7be8-4574-a1dd-d934df9c391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "As a research engineer, I can provide you with 10 professional visualizations commonly used to compare machine learning algorithm performances and visualize classifier performance:\n",
      "\n",
      "1. Receiver Operating Characteristic (ROC) Curve:\n",
      "   - Plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\n",
      "   - Useful for binary classification problems and comparing multiple classifiers.\n",
      "   - The Area Under the Curve (AUC) provides a single scalar value to compare classifiers.\n",
      "\n",
      "2. Precision-Recall Curve:\n",
      "   - Plots Precision against Recall at various threshold settings.\n",
      "   - Particularly useful for imbalanced datasets where ROC curves might be overly optimistic.\n",
      "   - The Area Under the Precision-Recall Curve (AUPRC) can be used as a single metric for comparison.\n",
      "\n",
      "3. Confusion Matrix Heatmap:\n",
      "   - A color-coded matrix showing True Positives, True Negatives, False Positives, and False Negatives.\n",
      "   - Useful for multi-class classification problems.\n",
      "   - Can be normalized to show percentages instead of raw counts.\n",
      "\n",
      "4. Learning Curves:\n",
      "   - Plots training and validation scores against the number of training samples.\n",
      "   - Helps diagnose bias and variance issues in the model.\n",
      "   - Can be used to determine if more data would be beneficial.\n",
      "\n",
      "5. Validation Curve:\n",
      "   - Plots training and validation scores against a specific hyperparameter.\n",
      "   - Useful for tuning individual hyperparameters and understanding their impact on model performance.\n",
      "\n",
      "6. Feature Importance Plot:\n",
      "   - Bar chart or horizontal bar plot showing the importance of each feature in the model.\n",
      "   - Commonly used with tree-based methods (e.g., Random Forests, Gradient Boosting).\n",
      "   - Can help in feature selection and understanding which features contribute most to the model's decisions.\n",
      "\n",
      "7. Lift Chart:\n",
      "   - Shows how much better your model is at predicting compared to a random selection.\n",
      "   - Particularly useful in marketing and customer targeting scenarios.\n",
      "\n",
      "8. Calibration Plot:\n",
      "   - Plots the predicted probabilities against the true probabilities.\n",
      "   - Helps assess whether a classifier is well-calibrated (i.e., its predicted probabilities match observed probabilities).\n",
      "\n",
      "9. Silhouette Plot:\n",
      "   - Used for clustering algorithms to visualize the quality of clusters.\n",
      "   - Shows how similar an object is to its own cluster compared to other clusters.\n",
      "\n",
      "10. t-SNE or UMAP Plot:\n",
      "    - Dimensionality reduction techniques that can visualize high-dimensional data in 2D or 3D.\n",
      "    - Useful for visualizing how well different algorithms separate classes in the feature space.\n",
      "    - Can be color-coded by true labels or predicted labels to show classification performance.\n",
      "\n",
      "These visualizations provide different perspectives on model performance and can be used in combination to gain a comprehensive understanding of how different algorithms compare and how well individual classifiers perform. The choice of visualization depends on the specific problem, the type of algorithm, and the aspects of performance you want to highlight.\n"
     ]
    }
   ],
   "source": [
    "print(\"As a research engineer, I can provide you with 10 professional visualizations commonly used to compare machine learning algorithm performances and visualize classifier performance:\\n\\n1. Receiver Operating Characteristic (ROC) Curve:\\n   - Plots the True Positive Rate (TPR) against the False Positive Rate (FPR) at various threshold settings.\\n   - Useful for binary classification problems and comparing multiple classifiers.\\n   - The Area Under the Curve (AUC) provides a single scalar value to compare classifiers.\\n\\n2. Precision-Recall Curve:\\n   - Plots Precision against Recall at various threshold settings.\\n   - Particularly useful for imbalanced datasets where ROC curves might be overly optimistic.\\n   - The Area Under the Precision-Recall Curve (AUPRC) can be used as a single metric for comparison.\\n\\n3. Confusion Matrix Heatmap:\\n   - A color-coded matrix showing True Positives, True Negatives, False Positives, and False Negatives.\\n   - Useful for multi-class classification problems.\\n   - Can be normalized to show percentages instead of raw counts.\\n\\n4. Learning Curves:\\n   - Plots training and validation scores against the number of training samples.\\n   - Helps diagnose bias and variance issues in the model.\\n   - Can be used to determine if more data would be beneficial.\\n\\n5. Validation Curve:\\n   - Plots training and validation scores against a specific hyperparameter.\\n   - Useful for tuning individual hyperparameters and understanding their impact on model performance.\\n\\n6. Feature Importance Plot:\\n   - Bar chart or horizontal bar plot showing the importance of each feature in the model.\\n   - Commonly used with tree-based methods (e.g., Random Forests, Gradient Boosting).\\n   - Can help in feature selection and understanding which features contribute most to the model's decisions.\\n\\n7. Lift Chart:\\n   - Shows how much better your model is at predicting compared to a random selection.\\n   - Particularly useful in marketing and customer targeting scenarios.\\n\\n8. Calibration Plot:\\n   - Plots the predicted probabilities against the true probabilities.\\n   - Helps assess whether a classifier is well-calibrated (i.e., its predicted probabilities match observed probabilities).\\n\\n9. Silhouette Plot:\\n   - Used for clustering algorithms to visualize the quality of clusters.\\n   - Shows how similar an object is to its own cluster compared to other clusters.\\n\\n10. t-SNE or UMAP Plot:\\n    - Dimensionality reduction techniques that can visualize high-dimensional data in 2D or 3D.\\n    - Useful for visualizing how well different algorithms separate classes in the feature space.\\n    - Can be color-coded by true labels or predicted labels to show classification performance.\\n\\nThese visualizations provide different perspectives on model performance and can be used in combination to gain a comprehensive understanding of how different algorithms compare and how well individual classifiers perform. The choice of visualization depends on the specific problem, the type of algorithm, and the aspects of performance you want to highlight.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1bec81a6-30ef-4d71-a47a-5bde57a4365a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = \"\"\"Confusion Matrix Heatmap:\n",
    "   - A color-coded matrix showing True Positives, True Negatives, False Positives, and False Negatives.\n",
    "   - Useful for multi-class classification problems.\n",
    "   - Can be normalized to show percentages instead of raw counts.\"\"\"\n",
    "\n",
    "plotting_code = gen(\"\"\"Given python classifaction predictions y_test and preds,\n",
    "which contain ground truth test labels and machine learning algorithm predictions,\n",
    "write high quality visualization code using matplotlib, which is: %s\"\"\"%(plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "705148da-42cf-463d-9609-b6b85fcd57fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_code = extract_code_snippets(plotting_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "792b8448-99fd-456a-b467-50b187ee7530",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
      "\n",
      "def plot_precision_recall_curve(y_test, preds):\n",
      "    # Calculate precision, recall, and thresholds\n",
      "    precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
      "    \n",
      "    # Calculate the Area Under the Precision-Recall Curve (AUPRC)\n",
      "    auprc = average_precision_score(y_test, preds)\n",
      "    \n",
      "    # Create the plot\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.plot(recall, precision, color='b', label=f'AUPRC = {auprc:.3f}')\n",
      "    \n",
      "    # Add the random classifier line\n",
      "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
      "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', color='r', label='Random Classifier')\n",
      "    \n",
      "    # Customize the plot\n",
      "    plt.xlabel('Recall', fontsize=12)\n",
      "    plt.ylabel('Precision', fontsize=12)\n",
      "    plt.title('Precision-Recall Curve', fontsize=14, fontweight='bold')\n",
      "    plt.legend(loc='lower left', fontsize=10)\n",
      "    \n",
      "    # Set axis limits\n",
      "    plt.xlim([0.0, 1.0])\n",
      "    plt.ylim([0.0, 1.05])\n",
      "    \n",
      "    # Add grid\n",
      "    plt.grid(True, linestyle='--', alpha=0.7)\n",
      "    \n",
      "    # Adjust layout and display\n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "\n",
      "# Example usage:\n",
      "# plot_precision_recall_curve(y_test, preds)\n"
     ]
    }
   ],
   "source": [
    "print(plot_code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "75bd7710-ac0d-498f-8a51-3ba7ab0b6f9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA24AAAMWCAYAAACJINXLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/av/WaAAAACXBIWXMAAA9hAAAPYQGoP6dpAABe00lEQVR4nO3deVwVZfvH8e8BFXABFxTUDPctd0xCM/URtc1c8udaIqltaiZparlb0uqeWZZrmpaP+ViaWS5ZSZYLarnvZYIC7ikoZ35/mKeOoDIGc0b5vJ/Xeb0e7nPPzDWDJ7i4rrnHYRiGIQAAAACAbXl5OgAAAAAAwPWRuAEAAACAzZG4AQAAAIDNkbgBAAAAgM2RuAEAAACAzZG4AQAAAIDNkbgBAAAAgM2RuAEAAACAzZG4AQAAAIDNkbgBuG3t2bNHzZs3V0BAgBwOhxYvXpyl+z948KAcDodmzpyZpfu9lTVu3FiNGzfO0n3+9ttv8vX11Q8//JCl+7Uzh8OhESNGuL6eOXOmHA6HDh48aGkcpUuXVrdu3VxfL1++XPnz59fx48ctjQMAQOIGIJvt27dPTz31lMqWLStfX1/5+/urQYMGmjBhgs6fP5+tx46MjNS2bdv06quvas6cOapbt262Hs9K3bp1k8PhkL+/f4bXcc+ePXI4HHI4HHrrrbdM7/+PP/7QiBEjFBcXlwXR/jujRo1SWFiYGjRo4Bq7cv41atSQYRjptnE4HOrdu7eVYeYI999/v8qXL6+YmBhPhwIAOQ6JG4Bss3TpUlWvXl2ffPKJWrZsqUmTJikmJkZ33nmnBgwYoL59+2bbsc+fP6/Y2Fh1795dvXv31mOPPaY77rgjS48REhKi8+fP6/HHH8/S/WZWrly59Oeff+rzzz9P997cuXPl6+t70/v+448/NHLkSNOJ24oVK7RixYqbPu7Vjh8/rlmzZunpp5/O8P1t27Zp0aJFWXY8u3r88cd1/vx5hYSEeDoUPfXUU3rvvfd05swZT4cCADkKiRuAbHHgwAF17NhRISEh2r59uyZMmKCePXuqV69e+vjjj7V9+3bddddd2Xb8K61cBQsWzLZjOBwO+fr6ytvbO9uOcT0+Pj5q2rSpPv7443TvzZs3Tw899JBlsfz555+SpDx58ihPnjxZtt+PPvpIuXLlUsuWLdO95+fnp4oVK2rUqFEZVt2yyqVLl5Samppt+88Mb29v+fr6yuFweDQOSXr00UeVkpKiTz/91NOhAECOQuIGIFu88cYbOnv2rD788EMVL1483fvly5d3q7hdunRJo0ePVrly5eTj46PSpUvrpZdeUkpKitt2pUuX1sMPP6zvv/9e9erVk6+vr8qWLavZs2e75owYMcJVmRgwYIAcDodKly4t6XKL3ZX//08jRoxI90vx119/rXvvvVcFCxZU/vz5ValSJb300kuu9691j9uqVavUsGFD5cuXTwULFlSrVq20Y8eODI+3d+9edevWTQULFlRAQICioqJcSVBmdO7cWV9++aVOnjzpGvv555+1Z88ede7cOd385ORk9e/fX9WrV1f+/Pnl7++vBx54QFu2bHHNWbNmje6++25JUlRUlKvl8sp5Nm7cWNWqVdPGjRt13333KW/evK7rcvU9bpGRkfL19U13/i1atFChQoX0xx9/XPf8Fi9erLCwMOXPnz/de15eXhoyZIi2bt2qzz777Lr7kaRjx46pe/fuCgoKkq+vr2rWrKlZs2a5zbnyPX3rrbc0fvx417/H7du3u75nu3fv1mOPPaaAgAAVLVpUQ4cOlWEY+u2339SqVSv5+/srODhYb7/9ttu+U1NTNWzYMIWGhiogIED58uVTw4YNtXr16hvGfvU9bldiyej1z3vSnE6nxo8fr7vuuku+vr4KCgrSU089pRMnTrjt3zAMvfLKK7rjjjuUN29eNWnSRL/++muGsRQrVkw1atTQ//73vxvGDQDIOiRuALLF559/rrJly6p+/fqZmt+jRw8NGzZMderU0bhx49SoUSPFxMSoY8eO6ebu3btX7dq1U7NmzfT222+rUKFC6tatm+sXzbZt22rcuHGSpE6dOmnOnDkaP368qfh//fVXPfzww0pJSdGoUaP09ttv65FHHrnhAhnffPONWrRooWPHjmnEiBGKjo7WunXr1KBBgwwXlmjfvr3OnDmjmJgYtW/fXjNnztTIkSMzHWfbtm3lcDjc2gXnzZunypUrq06dOunm79+/X4sXL9bDDz+ssWPHasCAAdq2bZsaNWrkSqKqVKmiUaNGSZKefPJJzZkzR3PmzNF9993n2k9SUpIeeOAB1apVS+PHj1eTJk0yjG/ChAkqWrSoIiMjlZaWJkl67733tGLFCk2aNEklSpS45rldvHhRP//8c4bncUXnzp1VoUKFG1bdzp8/r8aNG2vOnDnq0qWL3nzzTQUEBKhbt26aMGFCuvkzZszQpEmT9OSTT+rtt99W4cKFXe916NBBTqdTr732msLCwvTKK69o/PjxatasmUqWLKnXX39d5cuXV//+/bV27VrXdqdPn9YHH3ygxo0b6/XXX9eIESN0/PhxtWjRwnRLatu2bV3flyuv559/XtLlxOqKp556SgMGDHDdVxoVFaW5c+eqRYsWunjxomvesGHDNHToUNWsWVNvvvmmypYtq+bNm+vcuXMZHj80NFTr1q0zFTMA4F8yACCLnTp1ypBktGrVKlPz4+LiDElGjx493Mb79+9vSDJWrVrlGgsJCTEkGWvXrnWNHTt2zPDx8TFeeOEF19iBAwcMScabb77pts/IyEgjJCQkXQzDhw83/vmfxHHjxhmSjOPHj18z7ivHmDFjhmusVq1aRrFixYykpCTX2JYtWwwvLy+ja9eu6Y73xBNPuO2zTZs2RpEiRa55zH+eR758+QzDMIx27doZTZs2NQzDMNLS0ozg4GBj5MiRGV6DCxcuGGlpaenOw8fHxxg1apRr7Oeff053blc0atTIkGRMnTo1w/caNWrkNvbVV18ZkoxXXnnF2L9/v5E/f36jdevWNzzHvXv3GpKMSZMmXff8Z82aZUgyFi1a5HpfktGrVy/X1+PHjzckGR999JFrLDU11QgPDzfy589vnD592nUtJBn+/v7GsWPH3I555Xv25JNPusYuXbpk3HHHHYbD4TBee+011/iJEycMPz8/IzIy0m1uSkqK2z5PnDhhBAUFpft3IMkYPny46+sZM2YYkowDBw5keK2OHz9u3HnnnUb16tWNs2fPGoZhGN99950hyZg7d67b3OXLl7uNHzt2zMiTJ4/x0EMPGU6n0zXvpZdeMiS5ncMVY8aMMSQZCQkJGcYDAMh6VNwAZLnTp09LkgoUKJCp+cuWLZMkRUdHu42/8MILki4vcvJPVatWVcOGDV1fFy1aVJUqVdL+/ftvOuarXbk37n//+5+cTmemtjl69Kji4uLUrVs3twpNjRo11KxZM9d5/tPVi240bNhQSUlJrmuYGZ07d9aaNWsUHx+vVatWKT4+PsM2SenyfXFeXpf/05+WlqakpCRXG+imTZsyfUwfHx9FRUVlam7z5s311FNPadSoUWrbtq18fX313nvv3XC7pKQkSVKhQoWuO69Lly43rLotW7ZMwcHB6tSpk2ssd+7ceu6553T27Fl9++23bvMfffRRFS1aNMN99ejRw/X/vb29VbduXRmGoe7du7vGCxYsmO7fpLe3t+v+P6fTqeTkZF26dEl169Y1de2vlpaWpk6dOunMmTP67LPPlC9fPknSp59+qoCAADVr1kyJiYmuV2hoqPLnz+9q0fzmm2+UmpqqPn36uLULX6ngZeTK9yQxMfGm4wYAmEPiBiDL+fv7S1KmV507dOiQvLy8VL58ebfx4OBgFSxYUIcOHXIbv/POO9Pto1ChQunu2/k3OnTooAYNGqhHjx4KCgpSx44d9cknn1w3ibsSZ6VKldK9V6VKFSUmJqZrPbv6XK78QmzmXB588EEVKFBACxYs0Ny5c3X33Xenu5ZXOJ1OjRs3ThUqVJCPj48CAwNVtGhRbd26VadOncr0MUuWLGlqEZK33npLhQsXVlxcnCZOnOjWzncj10rGrvD29taQIUMUFxd3zWf1HTp0SBUqVHAlrVdUqVLF9f4/lSlT5prHu/p7FhAQIF9fXwUGBqYbv/r7OGvWLNWoUUO+vr4qUqSIihYtqqVLl5q69lcbMmSIVq1apXnz5qlcuXKu8T179ujUqVMqVqyYihYt6vY6e/asjh07Junvc69QoYLbfosWLXrNpPnK98QOi6UAQE6Ry9MBALj9+Pv7q0SJEvrll19MbZfZXwKvtYrjjX7Bv94xrtx/dYWfn5/Wrl2r1atXa+nSpVq+fLkWLFig//znP1qxYkWWrST5b87lCh8fH7Vt21azZs3S/v373R7cfLUxY8Zo6NCheuKJJzR69GgVLlxYXl5eev755zNdWZQuXx8zNm/e7EoUtm3b5lb5upYiRYpIylwS26VLF40ePVqjRo1S69atTcWWkeudX0bfs8x8Hz/66CN169ZNrVu31oABA1SsWDF5e3srJiZG+/btu6k4Fy9erNdff12jR4/W/fff7/ae0+lUsWLFNHfu3Ay3vVZFMTOufE+uTlYBANmHxA1Atnj44Yf1/vvvKzY2VuHh4dedGxISIqfTqT179rgqIJKUkJCgkydPZumzqwoVKuS2AuMVV1dcpMurFjZt2lRNmzbV2LFjNWbMGL388stavXq1IiIiMjwPSdq1a1e693bu3KnAwEBXG1tW69y5s6ZPny4vL68MF3S5YuHChWrSpIk+/PBDt/GTJ0+6/RKelZWUc+fOKSoqSlWrVlX9+vX1xhtvqE2bNq6VK6/lzjvvlJ+fnw4cOHDDY1ypunXr1i3D1Q5DQkK0detWOZ1Ot6rbzp07Xe9nt4ULF6ps2bJatGiR2/UdPnz4Te1v9+7dioyMVOvWrd1WO72iXLly+uabb9SgQYPrJqJXzn3Pnj0qW7asa/z48ePXTJoPHDjgqtYCAKxBqySAbPHiiy8qX7586tGjhxISEtK9v2/fPtdqfg8++KAkpVv5cezYsZKUpc8jK1eunE6dOqWtW7e6xo4ePZpuOfnk5OR029aqVUuS0j2i4IrixYurVq1amjVrllty+Msvv2jFihWu88wOTZo00ejRozV58mQFBwdfc563t3e6at6nn36qI0eOuI1dSTAzSnLNGjhwoA4fPqxZs2Zp7NixKl26tCIjI695Ha/InTu36tatqw0bNmTqOI899pjKly+f4aqcDz74oOLj47VgwQLX2KVLlzRp0iTlz59fjRo1MndSN+FKVe6f13/9+vWKjY01va+zZ8+qTZs2KlmypGbNmpVhot2+fXulpaVp9OjR6d67dOmS63sbERGh3Llza9KkSW6xXW8l1o0bN97wDzIAgKxFxQ1AtihXrpzmzZunDh06qEqVKuratauqVaum1NRUrVu3Tp9++qnreVM1a9ZUZGSk3n//fZ08eVKNGjXSTz/9pFmzZql169bXXGr+ZnTs2FEDBw5UmzZt9Nxzz+nPP//Uu+++q4oVK7otEDFq1CitXbtWDz30kEJCQnTs2DFNmTJFd9xxh+69995r7v/NN9/UAw88oPDwcHXv3l3nz5/XpEmTFBAQcN0Wxn/ryjPNbuThhx/WqFGjFBUVpfr162vbtm2aO3euW6VFuvz9K1iwoKZOnaoCBQooX758CgsLu+69XxlZtWqVpkyZouHDh7uW9Z8xY4YaN26soUOH6o033rju9q1atdLLL7+s06dPu+6dvBZvb2+9/PLLGS6a8uSTT+q9995Tt27dtHHjRpUuXVoLFy7UDz/8oPHjx2d6IZ1/4+GHH9aiRYvUpk0bPfTQQzpw4ICmTp2qqlWr6uzZs6b2NXLkSG3fvl1DhgxJV2EsV66cwsPD1ahRIz311FOKiYlRXFycmjdvrty5c2vPnj369NNPNWHCBLVr105FixZV//79FRMTo4cfflgPPvigNm/erC+//DLDVshjx45p69at6tWr17+6HgAAkzy1nCWAnGH37t1Gz549jdKlSxt58uQxChQoYDRo0MCYNGmSceHCBde8ixcvGiNHjjTKlClj5M6d2yhVqpQxePBgtzmGcflxAA899FC641y9DP21HgdgGIaxYsUKo1q1akaePHmMSpUqGR999FG6xwGsXLnSaNWqlVGiRAkjT548RokSJYxOnToZu3fvTneMq5fM/+abb4wGDRoYfn5+hr+/v9GyZUtj+/btbnOuHO/qxw3caNn3K/65HP61XOtxAC+88IJRvHhxw8/Pz2jQoIERGxub4TL+//vf/4yqVasauXLlcjvPRo0aGXfddVeGx/znfk6fPm2EhIQYderUMS5evOg2r1+/foaXl5cRGxt73XNISEgwcuXKZcyZMydT53/x4kWjXLly6R4HcGVfUVFRRmBgoJEnTx6jevXq6b531/t3c63v2bViufo6OZ1OY8yYMUZISIjh4+Nj1K5d2/jiiy8yfESFbvA4gMjISENShq+rl+9///33jdDQUMPPz88oUKCAUb16dePFF180/vjjD9ectLQ0Y+TIka5/F40bNzZ++eUXIyQkJN3+3n33XSNv3ryuRygAAKzhMAwTd8ADAGCx7t27a/fu3fruu+88HQok1a5dW40bN3Y95B4AYA0SNwCArR0+fFgVK1bUypUr1aBBA0+Hk6MtX75c7dq10/79+0090gEA8O+RuAEAAACAzbGqJAAAAADYHIkbAAAAAGTS2rVr1bJlS5UoUUIOh0OLFy++4TZr1qxRnTp15OPjo/Lly2vmzJmmj0viBgAAAACZdO7cOdWsWVPvvPNOpuYfOHBADz30kJo0aaK4uDg9//zz6tGjh7766itTx+UeNwAAAAC4CQ6HQ5999plat259zTkDBw7U0qVL9csvv7jGOnbsqJMnT2r58uWZPhYVNwAAAAA5WkpKik6fPu32SklJyZJ9x8bGKiIiwm2sRYsWio2NNbWfXFkSjc341e7t6RAA3MCJnyd7OgQAAG55vrfwb/N2+p19YKtAjRw50m1s+PDhGjFixL/ed3x8vIKCgtzGgoKCdPr0aZ0/f15+fn6Z2s8t/K0GAAAAgH9v8ODBio6Odhvz8fHxUDQZI3EDAAAAkKP5+PhkW6IWHByshIQEt7GEhAT5+/tnutomkbgBAAAA8ARHzlhuIzw8XMuWLXMb+/rrrxUeHm5qPznjagEAAABAFjh79qzi4uIUFxcn6fJy/3FxcTp8+LCky22XXbt2dc1/+umntX//fr344ovauXOnpkyZok8++UT9+vUzdVwSNwAAAADIpA0bNqh27dqqXbu2JCk6Olq1a9fWsGHDJElHjx51JXGSVKZMGS1dulRff/21atasqbffflsffPCBWrRoYeq4t+Vz3Oy0Qg2AjLGqJAAA/94tvapkaF9Ph+ByfuMET4dwQ1TcAAAAAMDmSNwAAAAAwOZu4eIqAAAAgFtWDllVMqtwtQAAAADA5qi4AQAAALCew+HpCG4pVNwAAAAAwOZI3AAAAADA5miVBAAAAGA9FicxhasFAAAAADZH4gYAAAAANkerJAAAAADrsaqkKVTcAAAAAMDmSNwAAAAAwOZolQQAAABgPVaVNIWrBQAAAAA2R8UNAAAAgPVYnMQUKm4AAAAAYHMkbgAAAABgc7RKAgAAALAei5OYwtUCAAAAAJsjcQMAAAAAm6NVEgAAAID1WFXSFCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwHqtKmsLVAgAAAACbo+IGAAAAwHosTmIKFTcAAAAAsDkSNwAAAACwOVolAQAAAFiPxUlM4WoBAAAAgM2RuAEAAACAzdEqCQAAAMB6tEqawtUCAAAAAJuj4gYAAADAel48x80MKm4AAAAAYHMkbgAAAABgc7RKAgAAALAei5OYwtUCAAAAAJsjcQMAAAAAm6NVEgAAAID1HKwqaQYVNwAAAACwORI3AAAAALA5WiUBAAAAWI9VJU3hagEAAACAzVFxAwAAAGA9FicxhYobAAAAANgciRsAAAAA2BytkgAAAACsx+IkpnC1AAAAAMDmSNwAAAAAwOZolQQAAABgPVaVNIWKGwAAAADYHIkbAAAAANgcrZIAAAAArMeqkqZwtQAAAADA5qi4AQAAALAei5OYQsUNAAAAAGyOxA0AAAAAbI5WSQAAAADWY3ESU7haAAAAAGBzJG4AAAAAYHO0SgIAAACwHqtKmkLFDQAAAABsjsQNAAAAAGyOVkkAAAAA1mNVSVO4WgAAAABgc1TcAAAAAFiPipspXC0AAAAAsDkSNwAAAACwOVolAQAAAFiP57iZQsUNAAAAAGyOxA0AAAAAbI5WSQAAAADWY1VJU7haAAAAAGBzJG4AAAAAYHO0SgIAAACwHqtKmkLFDQAAAABsjoobAAAAAOuxOIkpXC0AAAAAsDkSNwAAAACwOVolAQAAAFiPxUlMoeIGAAAAADZH4gYAAAAANkerJAAAAADLOWiVNIWKGwAAAADYHIkbAAAAANgcrZIAAAAALEerpDlU3AAAAADA5qi4AQAAALAeBTdTqLgBAAAAgM2RuAEAAACAzdEqCQAAAMByLE5iDhU3AAAAALA5EjcAAAAAsDlaJQEAAABYjlZJc6i4AQAAAIDNkbgBAAAAgM3RKgkAAADAcrRKmkPFDQAAAABsjoobAAAAAMtRcTOHihsAAAAA2ByJGwAAAADYHK2SAAAAAKxHp6QpVNxguQZ1ymnh+Ke0f8WrOr95slo2rnHDbRqGVtC6eQN1cv04/fK/4XqsZVi6OU+1v087l47UiR/Hae3s/qp7V0h2hA/kGPPnzdUDzf6ju2tXV5eO/6dtW7ded/6Kr75Uq4fv1921q+vR1i313dpv3d43DEPvTJqgpo3uVb06NfRk9246dOhgNp4BcPvjcwrkHCRusFw+Px9t231Ez8csyNT8kBJF9Nmkp7V2w26FdXxNk+et1rvDOisivIprTrvmdfT6C2306ntfKrzz69q6+4iWTOmlooXyZ9dpALe15V8u01tvxOipZ3tp/qefqVKlynrmqe5KSkrKcH7c5k0aNOAFtWnbTgsWLlaT/zTV8316ac+e3a45Mz6cpo/nztGQ4SP00cefyM/PT8882V0pKSlWnRZwW+FzCuQsJG6w3IoftmvklC+0ZPX1/yp4Rc929+rgkSQNGvuZdh1I0NQFa/XZyjj16dLENee5x/6jGYvWac6SH7Vzf7z6vDpf5y+kKrJ1eHadBnBbmzNrhtq2a6/WbR5VufLlNWT4SPn6+mrxov9mOH/uR7NV/96G6vZED5UtV069n3teVapW1fx5H0m6/Ff8uXNmq+dTz6jJfyJUsVJlvRLzho4fO6ZVK7+x8tSA2wafU9zqHA6HbV63AhI32F5YzTJavX6X29jX63YorEYZSVLuXN6qXaWUVv1jjmEYWrV+l+r9NQdA5l1MTdWO7b/qnvD6rjEvLy/dc099bd2yOcNttsbF6Z573P9QUr/BvdoaFydJOvL770pMPK6we/7eZ4ECBVS9Rs1r7hPAtfE5BXIejy5OkpiYqOnTpys2Nlbx8fGSpODgYNWvX1/dunVT0aJFPRkebCKoiL8Sks+4jR1LPq2AAn7y9cmtQv55lSuXt45dPSfptCqVDrIyVOC2cOLkCaWlpalIkSJu40WKFNGBA/sz3CYxMVFFigSmm5+YlPjX+8cvjwWm32diYmJWhQ7kGHxOgZzHY4nbzz//rBYtWihv3ryKiIhQxYoVJUkJCQmaOHGiXnvtNX311VeqW7fudfeTkpKSru/acKbJ4eWdbbEDAAAA+HdulRZFu/BY4tanTx/93//9n6ZOnZrum2YYhp5++mn16dNHsbGx191PTEyMRo4c6TbmHXS3chevl+UxwzMSkk4rqHABt7Fihf116sx5XUi5qMQTZ3XpUpqKXT2niL/ik05bGSpwWyhUsJC8vb3TLXCQlJSkwMDADLcJDAxUUlJi+vl//XU/MPByB0VSYpKKFi3mNqdS5cpZGT6QI/A5BXIej93jtmXLFvXr1y/DTNvhcKhfv36K+6vn+noGDx6sU6dOub1yBYVmQ8TwlPVbDqhxvUpuY03vqaz1Ww9Iki5eStPmHb+pSdjfcxwOh5rUq6if/poDIPNy58mjKlXv0vof//7DmdPp1Pr1sapRs3aG29SoVUvrf/zRbezH2HWqUauWJKnkHXcoMLCo1q//e59nz57Vtq1brrlPANfG5xS3A08vSMLiJJkUHBysn3766Zrv//TTTwoKuvH9ST4+PvL393d70SZpb/n88qhGxZKqUbGkJKl0ySKqUbGkSgUXkiSN6vOIPhj9uGv+tIXfq8wdRfRq31aqWDpIT/5fQz3arLYmzV3tmjPxo1WKalNfXVqGqVKZIE18qYPy+vlo9v/cf0AByJzHI6O0aOEnWrL4M+3ft0+vjBqh8+fPq3WbtpKklwe/qAnj3nbN7/JYV6374TvNmjldB/bv07vvTNKvv/yijp0fk3T5h3OXx7tq2nvvas2qldqze5eGDH5RRYsV03+aRnjiFIFbHp9TIGfxWKtk//799eSTT2rjxo1q2rSpK0lLSEjQypUrNW3aNL311lueCg/ZqE7VEK34oK/r6zf6PypJmrPkRz05/CMFB/qrVHBh1/uH/khSmz5T9Ub/turVubGOJJzUM6Pm6ZvYHa45C1dsUmCh/Br2zEMKKlJAW3cdUate76RbsARA5tz/wIM6kZysKZMnKjHxuCpVrqIp732gIn+1YMUfPSovx99/+6tVu45i3nhLkyeO16TxY3VnSGmNn/SOKlSo6JoT1b2nzp8/r1EjhunMmdOqXSdUU977QD4+PpafH3A74HMK5CwOwzAMTx18wYIFGjdunDZu3Ki0tDRJkre3t0JDQxUdHa327dvf1H79avfOyjABZIMTP0/2dAgAANzyfD26Rvy/U6Trx54OwSVpdidPh3BDHv1Wd+jQQR06dNDFixddy8wGBgYqd+7cngwLAAAAAGzFFjl67ty5Vbx4cU+HAQAAAAC2ZIvEDQAAAEAOc2ss5mgbHltVEgAAAACQOSRuAAAAAGBztEoCAAAAsNyt8uBru6DiBgAAAAA2R8UNAAAAgOWouJlDxQ0AAAAAbI7EDQAAAABsjlZJAAAAAJajVdIcKm4AAAAAYHMkbgAAAABgc7RKAgAAALAenZKmUHEDAAAAAJPeeecdlS5dWr6+vgoLC9NPP/103fnjx49XpUqV5Ofnp1KlSqlfv366cOFCpo9HxQ0AAACA5W7lxUkWLFig6OhoTZ06VWFhYRo/frxatGihXbt2qVixYunmz5s3T4MGDdL06dNVv3597d69W926dZPD4dDYsWMzdUwqbgAAAABgwtixY9WzZ09FRUWpatWqmjp1qvLmzavp06dnOH/dunVq0KCBOnfurNKlS6t58+bq1KnTDat0/0TiBgAAAACZlJqaqo0bNyoiIsI15uXlpYiICMXGxma4Tf369bVx40ZXorZ//34tW7ZMDz74YKaPS6skAAAAAMvZqVUyJSVFKSkpbmM+Pj7y8fFJNzcxMVFpaWkKCgpyGw8KCtLOnTsz3H/nzp2VmJioe++9V4Zh6NKlS3r66af10ksvZTpGKm4AAAAAcrSYmBgFBAS4vWJiYrJs/2vWrNGYMWM0ZcoUbdq0SYsWLdLSpUs1evToTO+DihsAAACAHG3w4MGKjo52G8uo2iZJgYGB8vb2VkJCgtt4QkKCgoODM9xm6NChevzxx9WjRw9JUvXq1XXu3Dk9+eSTevnll+XldeN6GhU3AAAAAJZzOBy2efn4+Mjf39/tda3ELU+ePAoNDdXKlStdY06nUytXrlR4eHiG2/z555/pkjNvb29JkmEYmbpeVNwAAAAAwITo6GhFRkaqbt26qlevnsaPH69z584pKipKktS1a1eVLFnS1W7ZsmVLjR07VrVr11ZYWJj27t2roUOHqmXLlq4E7kZI3AAAAADAhA4dOuj48eMaNmyY4uPjVatWLS1fvty1YMnhw4fdKmxDhgyRw+HQkCFDdOTIERUtWlQtW7bUq6++muljOozM1uZuIX61e3s6BAA3cOLnyZ4OAQCAW57vLVyGKfHUIk+H4PLHe209HcINcY8bAAAAANjcLZyjAwAAALhl2ecxbrcEKm4AAAAAYHMkbgAAAABgc7RKAgAAALCcw0GvpBlU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDlaJc2h4gYAAAAANkfiBgAAAAA2R6skAAAAAMvRKmkOFTcAAAAAsDkqbgAAAACsR8HNFCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwHIuTmEPFDQAAAABsjsQNAAAAAGyOVkkAAAAAlqNV0hwqbgAAAABgcyRuAAAAAGBztEoCAAAAsBytkuZQcQMAAAAAm6PiBgAAAMByVNzMoeIGAAAAADZH4gYAAAAANkerJAAAAADr0SlpChU3AAAAALA5EjcAAAAAsDlaJQEAAABYjlUlzaHiBgAAAAA2R+IGAAAAADZHqyQAAAAAy9EqaQ4VNwAAAACwOSpuAAAAACxHwc0cKm4AAAAAYHMkbgAAAABgc7RKAgAAALAci5OYQ8UNAAAAAGyOxA0AAAAAbI5WSQAAAACWo1PSHCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwHKtKmkPFDQAAAABsjoobAAAAAMtRcDOHihsAAAAA2ByJGwAAAADYHK2SAAAAACzn5UWvpBlU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDlWlTSHihsAAAAA2ByJGwAAAADYHK2SAAAAACznoFfSFCpuAAAAAGBzVNwAAAAAWI6CmzlU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDkWJzGHihsAAAAA2ByJGwAAAADYHK2SAAAAACxHq6Q5VNwAAAAAwOZI3AAAAADA5miVBAAAAGA5OiXNoeIGAAAAADZHxQ0AAACA5VicxBwqbgAAAABgcyRuAAAAAGBztEoCAAAAsBydkuZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOVYVdIcKm4AAAAAYHMkbgAAAABgc7RKAgAAALAcnZLmUHEDAAAAAJuj4gYAAADAcixOYg4VNwAAAACwORI3AAAAALA5WiUBAAAAWI5OSXOouAEAAACAzZG4AQAAAIDN0SoJAAAAwHKsKmkOFTcAAAAAsDkqbgAAAAAsR8HNnNsycTu0dpynQwBwA4GdZ3o6BAA3sP/DLp4OAcAN+BbI7ekQYBFaJQEAAADA5m7LihsAAAAAe2NxEnOouAEAAACAzZG4AQAAAIDN0SoJAAAAwHJ0SppDxQ0AAAAAbI7EDQAAAABsjlZJAAAAAJZjVUlzqLgBAAAAgM1RcQMAAABgOQpu5lBxAwAAAACbI3EDAAAAAJujVRIAAACA5VicxBwqbgAAAABgcyRuAAAAAGBztEoCAAAAsBytkuZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOXolDSHihsAAAAA2BwVNwAAAACWY3ESc6i4AQAAAIDNkbgBAAAAgM3RKgkAAADAcnRKmkPFDQAAAABsjsQNAAAAAGyOVkkAAAAAlmNVSXOouAEAAACAzZG4AQAAAIDN0SoJAAAAwHJ0SppDxQ0AAAAAbI6KGwAAAADLeVFyM4WKGwAAAADYHIkbAAAAANgcrZIAAAAALEenpDlU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDkHvZKmUHEDAAAAAJsjcQMAAAAAm6NVEgAAAIDlvOiUNIWKGwAAAADYHIkbAAAAAMs5HA7bvG7GO++8o9KlS8vX11dhYWH66aefrjv/5MmT6tWrl4oXLy4fHx9VrFhRy5Yty/TxaJUEAAAAABMWLFig6OhoTZ06VWFhYRo/frxatGihXbt2qVixYunmp6amqlmzZipWrJgWLlyokiVL6tChQypYsGCmj0niBgAAAAAmjB07Vj179lRUVJQkaerUqVq6dKmmT5+uQYMGpZs/ffp0JScna926dcqdO7ckqXTp0qaOSaskAAAAAMs5HPZ5paSk6PTp026vlJSUDONOTU3Vxo0bFRER4Rrz8vJSRESEYmNjM9xmyZIlCg8PV69evRQUFKRq1appzJgxSktLy/T1InEDAAAAkKPFxMQoICDA7RUTE5Ph3MTERKWlpSkoKMhtPCgoSPHx8Rlus3//fi1cuFBpaWlatmyZhg4dqrfffluvvPJKpmOkVRIAAABAjjZ48GBFR0e7jfn4+GTZ/p1Op4oVK6b3339f3t7eCg0N1ZEjR/Tmm29q+PDhmdoHiRsAAAAAyzlknwe5+fj4ZDpRCwwMlLe3txISEtzGExISFBwcnOE2xYsXV+7cueXt7e0aq1KliuLj45Wamqo8efLc8Li0SgIAAABAJuXJk0ehoaFauXKla8zpdGrlypUKDw/PcJsGDRpo7969cjqdrrHdu3erePHimUraJBI3AAAAADAlOjpa06ZN06xZs7Rjxw4988wzOnfunGuVya5du2rw4MGu+c8884ySk5PVt29f7d69W0uXLtWYMWPUq1evTB+TVkkAAAAAlvOyT6ekaR06dNDx48c1bNgwxcfHq1atWlq+fLlrwZLDhw/Ly+vvGlmpUqX01VdfqV+/fqpRo4ZKliypvn37auDAgZk+psMwDCPLz8TDjp256OkQANxA2e5zPR0CgBvY/2EXT4cA4AaKFcjt6RBu2iPv/+zpEFyWPHm3p0O4ISpuAAAAACzncNzCJTcP4B43AAAAALA5EjcAAAAAsDlaJQEAAABYjk5Jc6i4AQAAAIDNkbgBAAAAgM3RKgkAAADAcl70SppCxQ0AAAAAbI7EDQAAAABsjlZJAAAAAJajU9IcKm4AAAAAYHNU3AAAAABYzkHJzRQqbgAAAABgcyRuAAAAAGBztEoCAAAAsBydkuZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOW86JU0hYobAAAAANgciRsAAAAA2BytkgAAAAAsR6OkOVTcAAAAAMDmqLgBAAAAsJyDxUlMoeIGAAAAADZH4gYAAAAANkerJAAAAADLedEpaQoVNwAAAACwORI3AAAAALA5WiUBAAAAWI5VJc2h4gYAAAAANkfiBgAAAAA2l6lWySVLlmR6h4888shNBwMAAAAgZ6BT0pxMJW6tW7fO1M4cDofS0tL+TTwAAAAAgKtkKnFzOp3ZHQcAAACAHITFScz5V/e4XbhwIaviAAAAAABcg+nELS0tTaNHj1bJkiWVP39+7d+/X5I0dOhQffjhh1keIAAAAADkdKYTt1dffVUzZ87UG2+8oTx58rjGq1Wrpg8++CBLgwMAAABwe/Jy2Od1KzCduM2ePVvvv/++unTpIm9vb9d4zZo1tXPnziwNDgAAAABwE4nbkSNHVL58+XTjTqdTFy9ezJKgAAAAAAB/y9Sqkv9UtWpVfffddwoJCXEbX7hwoWrXrp1lgQEAAAC4fbGqpDmmE7dhw4YpMjJSR44ckdPp1KJFi7Rr1y7Nnj1bX3zxRXbECAAAAAA5mulWyVatWunzzz/XN998o3z58mnYsGHasWOHPv/8czVr1iw7YgQAAABwm3HY6HUrMF1xk6SGDRvq66+/zupYAAAAAAAZuKnETZI2bNigHTt2SLp831toaGiWBQUAAAAA+JvpxO33339Xp06d9MMPP6hgwYKSpJMnT6p+/fqaP3++7rjjjqyOEQAAAMBtxovFSUwxfY9bjx49dPHiRe3YsUPJyclKTk7Wjh075HQ61aNHj+yIEQAAAAByNNMVt2+//Vbr1q1TpUqVXGOVKlXSpEmT1LBhwywNDgAAAABwE4lbqVKlMnzQdlpamkqUKJElQQEAAAC4vdEpaY7pVsk333xTffr00YYNG1xjGzZsUN++ffXWW29laXAAAAAAgExW3AoVKuT2ZPNz584pLCxMuXJd3vzSpUvKlSuXnnjiCbVu3TpbAgUAAACAnCpTidv48eOzOQwAAAAAOYmDXklTMpW4RUZGZnccAAAAAIBruOkHcEvShQsXlJqa6jbm7+//rwICAAAAcPuj4GaO6cVJzp07p969e6tYsWLKly+fChUq5PYCAAAAAGQt04nbiy++qFWrVundd9+Vj4+PPvjgA40cOVIlSpTQ7NmzsyNGAAAAAMjRTLdKfv7555o9e7YaN26sqKgoNWzYUOXLl1dISIjmzp2rLl26ZEecAAAAAG4jXvRKmmK64pacnKyyZctKunw/W3JysiTp3nvv1dq1a7M2OgAAAACA+Ypb2bJldeDAAd15552qXLmyPvnkE9WrV0+ff/65ChYsmA0h4na06JOP9fGcGUpOSlS5CpX0/ICXVLVa9WvOX/3NV/rg3cmKP3pEd5QK0dN9+in83vtc7zesWy3D7Z55Llqduz6R5fEDOcGTLSqrb8tqCirop22HktV/+npt3Jd4zfnPPlhVPZpXUqnAfEo6naLF6w9q+LxNSrmY5ppTvFBejX4sVM1qlVRen1zaH39GT0/5Xpv3J1lxSsBth5+nQM5huuIWFRWlLVu2SJIGDRqkd955R76+vurXr58GDBiQ5QHi9rNyxZeaPO4Ndev5jD746FOVr1hJL/R5SieSM/7FbduWzRr58ot6qFUbfTj3UzVs/B+91P857d+7xzVn8fI1bq9Bw0bL4XCo8X+aWXVawG3l0fDSiul6t2IWxunegUv0y6FkLX65mYr6+2Y4//8alNGozqGK+TROof0W69mpP+jR8DIa0amOa07BfHn0zegHdfGSU23HfKO6/RZr8OyfdfJcaob7BHB9/DzFrc7hsM/rVmA6cevXr5+ee+45SVJERIR27typefPmafPmzerbt2+WB4jbz4K5s9WydTs99EgblSlbTv0HD5Ovr6+WLvksw/kL53+keuEN1LnrEypdppx6PNNHFStX1aJP5rnmFAkMdHt9/+1q1a5bTyXuKGXVaQG3ld4P36WZK3frozV7tfPIKT03LVbnUy/p8SYVMpx/T6Vi+nFXgj794YAOHz+rVVv/0Kc/7Fdo+UDXnH6tqutI0jk98+4P2rgvUYf+mncg4YxVpwXcVvh5CuQsphO3q4WEhKht27aqUaNGVsSD29zFixe1e+d2hYbd4xrz8vJS3Xr36NetWzLc5petW1S3XrjbWL3w+vplW8bzk5MSFfv9Wj3cqm3WBQ7kILm9vVS7bBGt3nbUNWYY0uptR1WvYtEMt/lx1zHVKhuo0HKXE7XSxfKrRe07tGLz7645D9UtpU37EzWnX2MdmNZBP7zeUt2aZpwIArg+fp4COU+m7nGbOHFipnd4pRoHZOTUyRNKS0tT4cJF3MYLFS6iQwcPZLhNclJiuvmFCwcqOSnje22+/GKJ8ubLq/uaRGRN0EAOU8TfR7m8vXTs5Hm38WMnz6tiiYAMt/n0hwMK9PfV16MfkEMO5c7lpQ9W7NRbn21zzSldrIB6NKusSUt/1ZufbVVouUC9GRWm1EtOzft2X7aeE3C74ecpbgeOW6VH0SYylbiNGzcuUztzOBxZmrj99ttvGj58uKZPn37NOSkpKUpJSXEfS/WSj49PlsWBW8uyJZ+p2f0P828AsFDDqsHq36aG+n3wozbsOa6ywf56I6qeBj5aQ6//d6skyctL2rQvSSM/3iRJ2nowWVXvLKjuzSqRuAE2xM9TwF4y1Sp54MCBTL3279+fpcElJydr1qxZ150TExOjgIAAt9fEt1/P0jiQdQIKFpK3t7eSr7px+kRykooUCcxwm8JFAtPNT05OVOEM5m/ZvFGHDx1Qy9a0dQA3K+l0ii6lOVWsoJ/beLGCfkq4qgp3xdAOtfXx2n2atWqPfv3tpD7/+bBGfLxJL7Su4brpO/7Eee38/aTbdrt+P6VSgfmy4zSA2xo/T3E78LLR61Zg+nEAWWnJkiXXfT8zieDgwYMVHR3tNnYq9Va5/DlP7ty5VbFyVW38ab3ua9xUkuR0OrXx5/Vq275ThttUq1FTG3/+Ue07P+4a27A+VtWq10w394v/LVKlKlVVvmLl7DkBIAe4mObU5v1JalytuL74+bCkyytuNa5WXO8t35nhNn4+3nIahtuY03n5a4ccMmTox13H0rVali/hr8PHz2XDWQC3N36eAjmPRxO31q1by+FwyLjqh/0/3aj31cfHJ10J/8KZi1kSH7JHhy5dNWbEy6pc9S5VuauaPp33kc6fP68HW7aWJL0ybLACixXT0737SZLadXxMfZ6M0vyPZir83vu08qsvtXP7rxrw0gi3/Z47e1ZrvlmhXs/3t/iMgNvP5C9+1Xu9GmrT/kRt3JuoXg9WVV6fXPpozeVlw9/vda/+SP5TI/5qe/xy4+/q/VBVbT2QrJ/3HFfZ4AIa0qG2vtz4myuhm7z0V60c/ZD6t6muResOKrR8oKKaVlSf92M9dp7ArYyfp0DO4tHErXjx4poyZYpatWqV4ftxcXEKDQ21OCpkt6bNH9DJEyf04dTJSk5KVPmKlfXWpKmuVo2E+KNyeP1dNa1es7aGv/q6pk2ZpPffmaA7SoVozFsTVba8+2p0K1d8KcMwFHH/g5aeD3A7+m/sQQX6+2pI+9oKKuinrQeT1WbM1zp26oIkqVRgfjn/8Te31/+7RYZhaGjH2ipROK8ST1/Qlxt/08iPN7vmbNqXpE5vrdLIzqEa9GgtHTp2RgNn/aRPvs/aNnsgp+DnKW51LE5ijsO4Xrkrmz3yyCOqVauWRo0aleH7W7ZsUe3ateV0Ok3t9xgVN8D2ynaf6+kQANzA/g+7eDoEADdQrEBuT4dw055bnHH7vSdMbG3/tmCPVtwGDBigc+eufW9D+fLltXr1agsjAgAAAAD7ualVPL777js99thjCg8P15EjRyRJc+bM0ffff29qPw0bNtT9999/zffz5cunRo0a3UyIAAAAAGzMy2Gf163AdOL23//+Vy1atJCfn582b97seobaqVOnNGbMmCwPEAAAAAByOtOJ2yuvvKKpU6dq2rRpyp37757aBg0aaNOmTVkaHAAAAADgJu5x27Vrl+6777504wEBATp58mRWxAQAAADgNnertCjahemKW3BwsPbu3Ztu/Pvvv1fZsmWzJCgAAAAAwN9MV9x69uypvn37avr06XI4HPrjjz8UGxur/v37a+jQodkRIwAAAIDbDM9xM8d04jZo0CA5nU41bdpUf/75p+677z75+Piof//+6tOnT3bECAAAAAA5munEzeFw6OWXX9aAAQO0d+9enT17VlWrVlX+/PmzIz4AAAAAyPFu+gHcefLkUdWqVbMyFgAAAAA5BIuTmGM6cWvSpMl1+1FXrVr1rwICAAAAALgznbjVqlXL7euLFy8qLi5Ov/zyiyIjI7MqLgAAAADAX0wnbuPGjctwfMSIETp79uy/DggAAADA7Y9FJc0x/Ry3a3nsscc0ffr0rNodAAAAAOAvWZa4xcbGytfXN6t2BwAAAAD4i+lWybZt27p9bRiGjh49qg0bNvAAbgAAAACZ4kWvpCmmE7eAgAC3r728vFSpUiWNGjVKzZs3z7LAAAAAAACXmUrc0tLSFBUVperVq6tQoULZFRMAAACA21yW3bOVQ5i6Xt7e3mrevLlOnjyZTeEAAAAAAK5mOtGtVq2a9u/fnx2xAAAAAAAyYDpxe+WVV9S/f3998cUXOnr0qE6fPu32AgAAAIAbcTjs87oVZPoet1GjRumFF17Qgw8+KEl65JFH5PjHWRqGIYfDobS0tKyPEgAAAABysEwnbiNHjtTTTz+t1atXZ2c8AAAAAICrZDpxMwxDktSoUaNsCwYAAABAzsBz3MwxdY+bg4sLAAAAAJYz9Ry3ihUr3jB5S05O/lcBAQAAAADcmUrcRo4cqYCAgOyKBQAAAEAOQTOfOaYSt44dO6pYsWLZFQsAAAAAIAOZTty4vw0AAABAVvEivTAl04uTXFlVEgAAAABgrUxX3JxOZ3bGAQAAAAC4BlP3uAEAAABAVuA5buaYeo4bAAAAAMB6JG4AAAAAYHO0SgIAAACwHJ2S5lBxAwAAAACbI3EDAAAAAJujVRIAAACA5XgAtzlU3AAAAADA5qi4AQAAALCcQ5TczKDiBgAAAAA2R+IGAAAAADZHqyQAAAAAy7E4iTlU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDlaJc2h4gYAAAAANkfiBgAAAAA2R6skAAAAAMs5HPRKmkHFDQAAAABsjoobAAAAAMuxOIk5VNwAAAAAwOZI3AAAAADA5miVBAAAAGA51iYxh4obAAAAANgciRsAAAAA2BytkgAAAAAs50WvpClU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDkewG0OFTcAAAAAsDkSNwAAAACWczjs87oZ77zzjkqXLi1fX1+FhYXpp59+ytR28+fPl8PhUOvWrU0dj8QNAAAAAExYsGCBoqOjNXz4cG3atEk1a9ZUixYtdOzYsetud/DgQfXv318NGzY0fUwSNwAAAAAwYezYserZs6eioqJUtWpVTZ06VXnz5tX06dOvuU1aWpq6dOmikSNHqmzZsqaPSeIGAAAAwHJectjmZUZqaqo2btyoiIiIv8/Fy0sRERGKjY295najRo1SsWLF1L1795u6XqwqCQAAACBHS0lJUUpKituYj4+PfHx80s1NTExUWlqagoKC3MaDgoK0c+fODPf//fff68MPP1RcXNxNx0jFDQAAAECOFhMTo4CAALdXTExMluz7zJkzevzxxzVt2jQFBgbe9H6ouAEAAACw3M2u5pgdBg8erOjoaLexjKptkhQYGChvb28lJCS4jSckJCg4ODjd/H379ungwYNq2bKla8zpdEqScuXKpV27dqlcuXI3jJHEDQAAAECOdq22yIzkyZNHoaGhWrlypWtJf6fTqZUrV6p3797p5leuXFnbtm1zGxsyZIjOnDmjCRMmqFSpUpk6LokbAAAAAJgQHR2tyMhI1a1bV/Xq1dP48eN17tw5RUVFSZK6du2qkiVLKiYmRr6+vqpWrZrb9gULFpSkdOPXQ+IGAAAAwHJeNmqVNKtDhw46fvy4hg0bpvj4eNWqVUvLly93LVhy+PBheXll7XIiDsMwjCzdow0cO3PR0yEAuIGy3ed6OgQAN7D/wy6eDgHADRQrkNvTIdy0qbEHPR2Cy9PhpT0dwg1RcQMAAABgOS87rU5yC+BxAAAAAABgcyRuAAAAAGBztEoCAAAAsBydkuZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOVYVdIcKm4AAAAAYHNU3AAAAABYjoKbOVTcAAAAAMDmSNwAAAAAwOZolQQAAABgOSpI5nC9AAAAAMDmSNwAAAAAwOZolQQAAABgOQfLSppCxQ0AAAAAbI7EDQAAAABsjlZJAAAAAJajUdIcKm4AAAAAYHNU3AAAAABYzovFSUyh4gYAAAAANkfiBgAAAAA2R6skAAAAAMvRKGkOFTcAAAAAsDkSNwAAAACwOVolAQAAAFiORSXNoeIGAAAAADZH4gYAAAAANkerJAAAAADLOeiVNIWKGwAAAADYHBU3AAAAAJajgmQO1wsAAAAAbI7EDQAAAABsjlZJAAAAAJZjcRJzqLgBAAAAgM2RuAEAAACAzdEqCQAAAMByNEqaQ8UNAAAAAGyOxA0AAAAAbI5WSQAAAACWY1VJc27LxM3fL7enQwBwA4nzunk6BAA3UOju3p4OAcANnN882dMhwCK3ZeIGAAAAwN64Z8scrhcAAAAA2ByJGwAAAADYHK2SAAAAACzH4iTmUHEDAAAAAJsjcQMAAAAAm6NVEgAAAIDlaJQ0h4obAAAAANgciRsAAAAA2BytkgAAAAAsx6KS5lBxAwAAAACbo+IGAAAAwHJeLE9iChU3AAAAALA5EjcAAAAAsDlaJQEAAABYjsVJzKHiBgAAAAA2R+IGAAAAADZHqyQAAAAAyzlYVdIUKm4AAAAAYHMkbgAAAABgc7RKAgAAALAcq0qaQ8UNAAAAAGyOihsAAAAAy3mxOIkpVNwAAAAAwOZI3AAAAADA5miVBAAAAGA5Ficxh4obAAAAANgciRsAAAAA2BytkgAAAAAsR6ukOVTcAAAAAMDmSNwAAAAAwOZolQQAAABgOQcP4DaFihsAAAAA2BwVNwAAAACW86LgZgoVNwAAAACwORI3AAAAALA5WiUBAAAAWI7FScyh4gYAAAAANkfiBgAAAAA2R6skAAAAAMs56JQ0hYobAAAAANgciRsAAAAA2BytkgAAAAAsx6qS5lBxAwAAAACbo+IGAAAAwHJeFNxMoeIGAAAAADZH4gYAAAAANkerJAAAAADLsTiJOVTcAAAAAMDmSNwAAAAAwOZolQQAAABgOQedkqZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOXolDSHihsAAAAA2BwVNwAAAACW82J1ElOouAEAAACAzZG4AQAAAIDN0SoJAAAAwHI0SppDxQ0AAAAAbI7EDQAAAABsjlZJAAAAANajV9IUKm4AAAAAYHNU3AAAAABYzkHJzRQqbgAAAABgcyRuAAAAAGBztEoCAAAAsJyDTklTqLgBAAAAgM2RuAEAAACAzdEqCQAAAMBydEqaQ8UNAAAAAGyOxA0AAAAAbI5WSQAAAADWo1fSFCpuAAAAAGBzVNwAAAAAWM5Byc0UKm4AAAAAYHMkbgAAAABgc7RKAgAAALCcg05JU6i4AQAAAIDNkbgBAAAAgM3RKgkAAADAcnRKmkPFDQAAAABsjsQNAAAAAGyOVkkAAAAA1qNX0hQqbgAAAABgc1TcAAAAAFjOQcnNFCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwnINOSVOouAEAAACASe+8845Kly4tX19fhYWF6aeffrrm3GnTpqlhw4YqVKiQChUqpIiIiOvOzwiJGwAAAACYsGDBAkVHR2v48OHatGmTatasqRYtWujYsWMZzl+zZo06deqk1atXKzY2VqVKlVLz5s115MiRTB/TYRiGkVUnYBcXLnk6AgAAbn2F7u7t6RAA3MD5zZM9HcJN23L4jKdDcKl5ZwFT88PCwnT33Xdr8uTL19/pdKpUqVLq06ePBg0adMPt09LSVKhQIU2ePFldu3bN1DGpuAEAAADI0VJSUnT69Gm3V0pKSoZzU1NTtXHjRkVERLjGvLy8FBERodjY2Ewd788//9TFixdVuHDhTMdI4gYAAAAgR4uJiVFAQIDbKyYmJsO5iYmJSktLU1BQkNt4UFCQ4uPjM3W8gQMHqkSJEm7J342wqiQAAAAA69loVcnBgwcrOjrabczHxydbjvXaa69p/vz5WrNmjXx9fTO9HYkbAAAAgBzNx8cn04laYGCgvL29lZCQ4DaekJCg4ODg62771ltv6bXXXtM333yjGjVqmIqRVkkAAAAAlnPY6H9m5MmTR6GhoVq5cqVrzOl0auXKlQoPD7/mdm+88YZGjx6t5cuXq27duqavFxU3AAAAADAhOjpakZGRqlu3rurVq6fx48fr3LlzioqKkiR17dpVJUuWdN0n9/rrr2vYsGGaN2+eSpcu7boXLn/+/MqfP3+mjkniBgAAAAAmdOjQQcePH9ewYcMUHx+vWrVqafny5a4FSw4fPiwvr7+bG999912lpqaqXbt2bvsZPny4RowYkalj8hw3AACQIZ7jBtjfrfwct22/n/V0CC7V78hc1cuTuMcNAAAAAGyOxA0AAAAAbI573AAAAABYzkaPcbslUHEDAAAAAJsjcQMAAAAAm6NVEgAAAID16JU0hYobAAAAANgcFTcAAAAAlnNQcjOFihsAAAAA2ByJGwAAAADYHK2SAAAAACznoFPSFCpu8Ij58+bqgWb/0d21q6tLx//Ttq1brzt/xVdfqtXD9+vu2tX1aOuW+m7tt27vG4ahdyZNUNNG96penRp6sns3HTp0MBvPALj98TkF7K1BnXJaOP4p7V/xqs5vnqyWjWvccJuGoRW0bt5AnVw/Tr/8b7geaxmWbs5T7e/TzqUjdeLHcVo7u7/q3hWSHeEDMInEDZZb/uUyvfVGjJ56tpfmf/qZKlWqrGee6q6kpKQM58dt3qRBA15Qm7bttGDhYjX5T1M936eX9uzZ7Zoz48Np+njuHA0ZPkIfffyJ/Pz89MyT3ZWSkmLVaQG3FT6ngP3l8/PRtt1H9HzMgkzNDylRRJ9NelprN+xWWMfXNHnear07rLMiwqu45rRrXkevv9BGr773pcI7v66tu49oyZReKloof3adBoBMInGD5ebMmqG27dqrdZtHVa58eQ0ZPlK+vr5avOi/Gc6f+9Fs1b+3obo90UNly5VT7+eeV5WqVTV/3keSLv8Vf+6c2er51DNq8p8IVaxUWa/EvKHjx45p1cpvrDw14LbB5xSwvxU/bNfIKV9oyerrV8Ov6NnuXh08kqRBYz/TrgMJmrpgrT5bGac+XZq45jz32H80Y9E6zVnyo3buj1efV+fr/IVURbYOz67TQA7msNHrVkDiBktdTE3Vju2/6p7w+q4xLy8v3XNPfW3dsjnDbbbGxemee9x/YNRvcK+2xsVJko78/rsSE48r7J6/91mgQAFVr1HzmvsEcG18ToHbU1jNMlq9fpfb2NfrdiisRhlJUu5c3qpdpZRW/WOOYRhatX6X6v01B4DneDxxO3/+vL7//ntt37493XsXLlzQ7NmzPRAVssuJkyeUlpamIkWKuI0XKVJEiYmJGW6TmJioIkUC089PSvzr/eOXxwIzv08A18bnFLg9BRXxV0LyGbexY8mnFVDAT74+uRVYKL9y5fLWsavnJJ1WcBF/K0MFkAGPJm67d+9WlSpVdN9996l69epq1KiRjh496nr/1KlTioqKuu4+UlJSdPr0abcX90sAAAAANufp/shbrFfSo4nbwIEDVa1aNR07dky7du1SgQIF1KBBAx0+fDjT+4iJiVFAQIDb683XY7IxavwbhQoWkre3d7oFDpKSkhQYGJjhNoGBgUpKSkw//6+/7gcGFr08lpj5fQK4Nj6nwO0pIem0ggoXcBsrVthfp86c14WUi0o8cVaXLqWp2NVzivgrPum0laECyIBHE7d169YpJiZGgYGBKl++vD7//HO1aNFCDRs21P79+zO1j8GDB+vUqVNurwEDB2dz5LhZufPkUZWqd2n9j7GuMafTqfXrY1WjZu0Mt6lRq5bW//ij29iPsetUo1YtSVLJO+5QYGBRrV//9z7Pnj2rbVu3XHOfAK6Nzylwe1q/5YAa16vkNtb0nspav/WAJOnipTRt3vGbmoT9PcfhcKhJvYr66a85QFZy2Oh/twKPJm7nz59Xrlx/PwPc4XDo3XffVcuWLdWoUSPt3r37Oltf5uPjI39/f7eXj49PdoaNf+nxyCgtWviJliz+TPv37dMro0bo/Pnzat2mrSTp5cEvasK4t13zuzzWVet++E6zZk7Xgf379O47k/TrL7+oY+fHJF3+d9Pl8a6a9t67WrNqpfbs3qUhg19U0WLF9J+mEZ44ReCWx+cUsL98fnlUo2JJ1ahYUpJUumQR1ahYUqWCC0mSRvV5RB+Mftw1f9rC71XmjiJ6tW8rVSwdpCf/r6EebVZbk+auds2Z+NEqRbWpry4tw1SpTJAmvtRBef18NPt/7n+YAWC9XDeekn0qV66sDRs2qEqVKm7jkydPliQ98sgjnggL2ez+Bx7UieRkTZk8UYmJx1WpchVNee8DFfmrXSr+6FF5Of7+m0Kt2nUU88ZbmjxxvCaNH6s7Q0pr/KR3VKFCRdecqO49df78eY0aMUxnzpxW7TqhmvLeByTxwE3icwrYX52qIVrxQV/X12/0f1SSNGfJj3py+EcKDvRXqeDCrvcP/ZGkNn2m6o3+bdWrc2MdSTipZ0bN0zexO1xzFq7YpMBC+TXsmYcUVKSAtu46ola93km3YAkA6zkMwzA8dfCYmBh99913WrZsWYbvP/vss5o6daqcTqep/V64lBXRAQCQsxW6u7enQwBwA+c3T/Z0CDdtV/yfng7BpVJwXk+HcEMeTdyyC4kbAAD/HokbYH8kblnjVkjcPP4cNwAAAADA9Xn0HjcAAAAAOdOtsZajfVBxAwAAAACbI3EDAAAAAJujVRIAAACA9eiVNIWKGwAAAADYHBU3AAAAAJZzUHIzhYobAAAAANgciRsAAAAA2BytkgAAAAAs56BT0hQqbgAAAABgcyRuAAAAAGBztEoCAAAAsBydkuZQcQMAAAAAmyNxAwAAAACbo1USAAAAgPXolTSFihsAAAAA2BwVNwAAAACWc1ByM4WKGwAAAADYHIkbAAAAANgcrZIAAAAALOegU9IUKm4AAAAAYHMkbgAAAABgc7RKAgAAALAcnZLmUHEDAAAAAJsjcQMAAAAAm6NVEgAAAID16JU0hYobAAAAANgcFTcAAAAAlnNQcjOFihsAAAAA2ByJGwAAAADYHK2SAAAAACznoFPSFCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwHJ2S5lBxAwAAAACbo+IGAAAAwHIsTmIOFTcAAAAAsDkSNwAAAACwOVolAQAAAHgAvZJmUHEDAAAAAJsjcQMAAAAAm6NVEgAAAIDlWFXSHCpuAAAAAGBzJG4AAAAAYHO0SgIAAACwHJ2S5lBxAwAAAACbo+IGAAAAwHIsTmIOFTcAAAAAsDkSNwAAAACwOVolAQAAAFjOwfIkplBxAwAAAACbI3EDAAAAAJujVRIAAACA9eiUNIWKGwAAAADYHIkbAAAAANgcrZIAAAAALEenpDlU3AAAAADA5qi4AQAAALCcg5KbKVTcAAAAAMDmSNwAAAAAwOZolQQAAABgOQfLk5hCxQ0AAAAAbI7EDQAAAABsjlZJAAAAANajU9IUKm4AAAAAYHMkbgAAAABgc7RKAgAAALAcnZLmUHEDAAAAAJuj4gYAAADAcg5KbqZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOUcLE9iChU3AAAAALA5EjcAAAAAsDlaJQEAAABYjlUlzaHiBgAAAAA2R+IGAAAAADZH4gYAAAAANkfiBgAAAAA2x+IkAAAAACzH4iTmUHEDAAAAAJsjcQMAAAAAm6NVEgAAAIDlHKJX0gwqbgAAAABgcyRuAAAAAGBztEoCAAAAsByrSppDxQ0AAAAAbI7EDQAAAABsjlZJAAAAAJajU9IcKm4AAAAAYHNU3AAAAABYj5KbKVTcAAAAAMDmSNwAAAAAwOZolQQAAABgOQe9kqZQcQMAAAAAmyNxAwAAAACbo1USAAAAgOUcdEqaQsUNAAAAAGyOxA0AAAAAbI5WSQAAAACWo1PSHCpuAAAAAGBzVNwAAAAAWI+SmylU3AAAAADA5kjcAAAAAMDmaJUEAAAAYDkHvZKmUHEDAAAAAJPeeecdlS5dWr6+vgoLC9NPP/103fmffvqpKleuLF9fX1WvXl3Lli0zdTwSNwAAAAAwYcGCBYqOjtbw4cO1adMm1axZUy1atNCxY8cynL9u3Tp16tRJ3bt31+bNm9W6dWu1bt1av/zyS6aP6TAMw8iqE7CLC5c8HQEAALe+Qnf39nQIAG7g/ObJng7hptnpd3ZfkzeQhYWF6e6779bkyZevv9PpVKlSpdSnTx8NGjQo3fwOHTro3Llz+uKLL1xj99xzj2rVqqWpU6dm6phU3AAAAAAgk1JTU7Vx40ZFRES4xry8vBQREaHY2NgMt4mNjXWbL0ktWrS45vyMsDgJAAAAgBwtJSVFKSkpbmM+Pj7y8fFJNzcxMVFpaWkKCgpyGw8KCtLOnTsz3H98fHyG8+Pj4zMd422ZuJktdcLeUlJSFBMTo8GDB2f44QHgeXxOb0+3cgsW0uNzCrux0+/sI16J0ciRI93Ghg8frhEjRngmoAzQKgnbS0lJ0ciRI9P9FQSAffA5BeyPzylwbYMHD9apU6fcXoMHD85wbmBgoLy9vZWQkOA2npCQoODg4Ay3CQ4ONjU/IyRuAAAAAHI0Hx8f+fv7u72uVZnOkyePQkNDtXLlSteY0+nUypUrFR4enuE24eHhbvMl6euvv77m/IzYqEAJAAAAAPYXHR2tyMhI1a1bV/Xq1dP48eN17tw5RUVFSZK6du2qkiVLKiYmRpLUt29fNWrUSG+//bYeeughzZ8/Xxs2bND777+f6WOSuAEAAACACR06dNDx48c1bNgwxcfHq1atWlq+fLlrAZLDhw/Ly+vv5sb69etr3rx5GjJkiF566SVVqFBBixcvVrVq1TJ9zNvyOW64vXAzNWB/fE4B++NzCtzaSNwAAAAAwOZYnAQAAAAAbI7EDQAAAABsjsQNAAAAAGyOxA0AAAAAbI7EDbbndDqVlpbm6TAAALgtsC4dcGviOW6wte3bt2vMmDGKj49XhQoV9Pjjj6t+/fqeDgvAP6Slpcnb29vTYQC4jnPnzsnpdMowDPn7+3s6HAA3gYobbGvXrl2qX7++0tLSdPfddys2NlZ9+/bVxIkTPR0agL/s3r1b48eP19GjRz0dCoBr2L59u9q2batGjRqpSpUqmjt3riQqb8CthoobbMkwDM2ePVstWrTQxx9/LEl66aWXNHHiRM2YMUMXLlzQiy++6OEogZxt7969Cg8P14kTJ5SUlKTo6GgFBgZ6OiwA/7B9+3bdd9996tq1q+rWrauNGzcqKipKd911l2rVquXp8ACYQOIGW3I4HPrjjz8UHx/vGitQoICee+45+fr6av78+SpZsqS6dOniwSiBnOvcuXOKiYnRI488orvvvlu9e/fWpUuX9OKLL5K8ATaRnJysfv36qUuXLho7dqwkqXPnztq0aZOmT5+uiRMnyjAMORwOD0cKIDNI3GA7V36I1KlTR3v27NGuXbtUqVIlSZeTtyeeeEK7du3SlClT1KZNG+XNm9fDEQM5j5eXl0JDQ1WkSBF16NBBgYGB6tixoySRvAE2cfHiRZ08eVLt2rWTdHmxLy8vL5UpU0bJycmSRNIG3EIcBg3OsKl9+/bpnnvu0SOPPKIJEyYof/78rqTut99+U0hIiJYtW6b777/f06ECOdK5c+eUL18+19cLFixQp06d9MILL2jQoEEqUqSInE6nDh06pDJlyngwUiDn2rNnjypUqCDpciKXO3duDR06VIcOHdLs2bNd886ePav8+fN7KkwAmUDFDbZVrlw5ffLJJ3rggQfk5+enESNGuP6Knzt3btWoUUMBAQEejhLIua4kbWlpafLy8lKHDh1kGIY6d+4sh8Oh559/Xm+99ZYOHTqkOXPmUB0HPOBK0uZ0OpU7d25Jlztbjh075poTExMjHx8fPffcc8qVi18NAbvi0wlba9KkiT799FP93//9n44ePar27durRo0amj17to4dO6ZSpUp5OkQgx/P29pZhGHI6nerYsaMcDocef/xxLVmyRPv27dPPP/9M0gZ4mJeXl9v9bF5elxcWHzZsmF555RVt3ryZpA2wOVolcUvYtGmToqOjdfDgQeXKlUve3t6aP3++ateu7enQAPzlyo8Th8Ohpk2bKi4uTmvWrFH16tU9HBkA6e973EaMGKGjR4+qQoUKGjJkiNatW6c6dep4OjwAN8CfVnBLqFOnjpYsWaLk5GSdOXNGxYsXZ/EDwGYcDofS0tI0YMAArV69WnFxcSRtgI1cqbLlzp1b06ZNk7+/v77//nuSNuAWQcUNAJBl0tLSNHPmTIWGhvKMKMCmNmzYoHr16umXX35R1apVPR0OgEwicQMAZCmeCwXY39WrwgKwPxI3AAAAALA5L08HAAAAAAC4PhI3AAAAALA5EjcAAAAAsDkSNwAAAACwORI3AAAAALA5EjcAAAAAsDkSNwDIQbp166bWrVu7vm7cuLGef/55y+NYs2aNHA6HTp48ec05DodDixcvzvQ+R4wY8a8f+n3w4EE5HA7FxcX9q/0AAJDVSNwAwMO6desmh8Mhh8OhPHnyqHz58ho1apQuXbqU7cdetGiRRo8enam5mUm2AABA9sjl6QAAANL999+vGTNmKCUlRcuWLVOvXr2UO3duDR48ON3c1NRU5cmTJ0uOW7hw4SzZDwAAyF5U3ADABnx8fBQcHKyQkBA988wzioiI0JIlSyT93d746quvqkSJEqpUqZIk6bffflP79u1VsGBBFS5cWK1atdLBgwdd+0xLS1N0dLQKFiyoIkWK6MUXX5RhGG7HvbpVMiUlRQMHDlSpUqXk4+Oj8uXL68MPP9TBgwfVpEkTSVKhQoXkcDjUrVs3SZLT6VRMTIzKlCkjPz8/1axZUwsXLnQ7zrJly1SxYkX5+fmpSZMmbnFm1sCBA1WxYkXlzZtXZcuW1dChQ3Xx4sV089577z2VKlVKefPmVfv27XXq1Cm39z/44ANVqVJFvr6+qly5sqZMmWI6FgAArEbiBgA25Ofnp9TUVNfXK1eu1K5du/T111/riy++0MWLF9WiRQsVKFBA3333nX744Qflz59f999/v2u7t99+WzNnztT06dP1/fffKzk5WZ999tl1j9u1a1d9/PHHmjhxonbs2KH33ntP+fPnV6lSpfTf//5XkrRr1y4dPXpUEyZMkCTFxMRo9uzZmjp1qn799Vf169dPjz32mL799ltJlxPMtm3bqmXLloqLi1OPHj00aNAg09ekQIECmjlzprZv364JEyZo2rRpGjdunNucvXv36pNPPtHnn3+u5cuXa/PmzXr22Wdd78+dO1fDhg3Tq6++qh07dmjMmDEaOnSoZs2aZToeAAAsZQAAPCoyMtJo1aqVYRiG4XQ6ja+//trw8fEx+vfv73o/KCjISElJcW0zZ84co1KlSobT6XSNpaSkGH5+fsZXX31lGIZhFC9e3HjjjTdc71+8eNG44447XMcyDMNo1KiR0bdvX8MwDGPXrl2GJOPrr7/OMM7Vq1cbkowTJ064xi5cuGDkzZvXWLdundvc7t27G506dTIMwzAGDx5sVK1a1e39gQMHptvX1SQZn3322TXff/PNN43Q0FDX18OHDze8vb2N33//3TX25ZdfGl5eXsbRo0cNwzCMcuXKGfPmzXPbz+jRo43w8HDDMAzjwIEDhiRj8+bN1zwuAACewD1uAGADX3zxhfLnz6+LFy/K6XSqc+fOGjFihOv96tWru93XtmXLFu3du1cFChRw28+FCxe0b98+nTp1SkePHlVYWJjrvVy5cqlu3brp2iWviIuLk7e3txo1apTpuPfu3as///xTzZo1cxtPTU1V7dq1JUk7duxwi0OSwsPDM32MKxYsWKCJEydq3759Onv2rC5duiR/f3+3OXfeeadKlizpdhyn06ldu3apQIEC2rdvn7p3766ePXu65ly6dEkBAQGm4wEAwEokbgBgA02aNNG7776rPHnyqESJEsqVy/0/z/ny5XP7+uzZswoNDdXcuXPT7ato0aI3FYOfn5/pbc6ePStJWrp0qVvCJF2+by+rxMbGqkuXLho5cqRatGihgIAAzZ8/X2+//bbpWKdNm5YukfT29s6yWAEAyA4kbgBgA/ny5VP58uUzPb9OnTpasGCBihUrlq7qdEXx4sW1fv163XfffZIuV5Y2btyoOnXqZDi/evXqcjqd+vbbbxUREZHu/SsVv7S0NNdY1apV5ePjo8OHD1+zUlelShXXQitX/Pjjjzc+yX9Yt26dQkJC9PLLL7vGDh06lG7e4cOH9ccff6hEiRKu43h5ealSpUoKCgpSiRIltH//fnXp0sXU8QEA8DQWJwGAW1CXLl0UGBioVq1a6bvvvtOBAwe0Zs0aPffcc/r9998lSX379tVrr72mxYsXa+fOnXr22Wev+wy20qVLKzIyUk888YQWL17s2ucnn3wiSQoJCZHD4dAXX3yh48eP6+zZsypQoID69++vfv36adasWdq3b582bdqkSZMmuRb8ePrpp7Vnzx4NGDBAu3bt0rx58zRz5kxT51uhQgUdPnxY8+fP1759+zRx4sQMF1rx9fVVZGSktmzZou+++07PPfec2rdvr+DgYEnSyJEjFRMTo4kTJ2r37t3atm2bZsyYobFjx5qKBwAAq5G4AcAtKG/evFq7dq3uvPNOtW3bVlWqVFH37t114cIFVwXuhRde0OOPP67IyEiFh4erQIECatOmzXX3++6776pdu3Z69tlnVblyZfXs2VPnzp2TJJUsWVIjR47UoEGDFBQUpN69e0uSRo8eraFDhyomJkZVqlTR/fffr6VLl6pMmTKSLt939t///leLFy9WzZo1NXXqVI0ZM8bU+T7yyCPq16+fevfurVq1amndunUaOnRounnly5dX27Zt9eCDD6p58+aqUaOG23L/PXr00AcffKAZM2aoevXqatSokWbOnOmKFQAAu3IY17pLHQAAAABgC1TcAAAAAMDmSNwAAAAAwOZI3AAAAADA5kjcAAAAAMDmSNwAAAAAwOZI3AAAAADA5kjcAAAAAMDmSNwAAAAAwOZI3AAAAADA5kjcAAAAAMDmSNwAAAAAwOZI3AAAAADA5v4fSlmk2BM2LNoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exec(plot_code[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ae89dc4-2b84-4160-a06a-070787a8722b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m model \u001b[38;5;241m=\u001b[39m mo\u001b[38;5;241m.\u001b[39mMultiLevelAbstractionKNN(n_neighbors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, n_levels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     35\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(x_test, y_test)\n\u001b[0;32m---> 36\u001b[0m plot_decision_boundary(model, x_test, y_test, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMultiLevelAbstractionKNN Decision Boundary\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilevel_abstraction_knn_decision_boundary.png\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn [7], line 17\u001b[0m, in \u001b[0;36mplot_decision_boundary\u001b[0;34m(model, X, y, title, filename)\u001b[0m\n\u001b[1;32m     13\u001b[0m xx, yy \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmeshgrid(np\u001b[38;5;241m.\u001b[39marange(x_min, x_max, \u001b[38;5;241m0.1\u001b[39m),\n\u001b[1;32m     14\u001b[0m                      np\u001b[38;5;241m.\u001b[39marange(y_min, y_max, \u001b[38;5;241m0.1\u001b[39m))\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Make predictions on the mesh grid\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m Z \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpca\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minverse_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mxx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m Z \u001b[38;5;241m=\u001b[39m Z\u001b[38;5;241m.\u001b[39mreshape(xx\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Plot the decision boundary\u001b[39;00m\n",
      "File \u001b[0;32m~/Dropbox/python_new/Misc/metaomni/multilevel_abstraction_knn.py:51\u001b[0m, in \u001b[0;36mMultiLevelAbstractionKNN.predict\u001b[0;34m(self, X_test)\u001b[0m\n\u001b[1;32m     48\u001b[0m     X_abstracted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpcas[level]\u001b[38;5;241m.\u001b[39mtransform(X_scaled)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Get predictions for this level\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     level_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodels\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_abstracted\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mappend(level_predictions)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;66;03m# Combine predictions from all levels\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/neighbors/_classification.py:279\u001b[0m, in \u001b[0;36mKNeighborsClassifier.predict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, classes_k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(classes_):\n\u001b[1;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 279\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m \u001b[43m_mode\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_y\u001b[49m\u001b[43m[\u001b[49m\u001b[43mneigh_ind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    281\u001b[0m         mode, _ \u001b[38;5;241m=\u001b[39m weighted_mode(_y[neigh_ind, k], weights, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/sklearn/utils/fixes.py:102\u001b[0m, in \u001b[0;36m_mode\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mode\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[1;32m    101\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.9.0\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 102\u001b[0m         mode \u001b[38;5;241m=\u001b[39m \u001b[43mscipy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstats\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sp_version \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m parse_version(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1.10.999\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    104\u001b[0m             \u001b[38;5;66;03m# scipy.stats.mode has changed returned array shape with axis=None\u001b[39;00m\n\u001b[1;32m    105\u001b[0m             \u001b[38;5;66;03m# and keepdims=True, see https://github.com/scipy/scipy/pull/17561\u001b[39;00m\n\u001b[1;32m    106\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:603\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    600\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[38;5;241m*\u001b[39msamples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    602\u001b[0m x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmoveaxis(x, axis, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 603\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_along_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhypotest_fun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    604\u001b[0m res \u001b[38;5;241m=\u001b[39m _add_reduced_axes(res, reduced_axes, keepdims)\n\u001b[1;32m    605\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tuple_to_result(\u001b[38;5;241m*\u001b[39mres)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/numpy/lib/shape_base.py:402\u001b[0m, in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    400\u001b[0m buff[ind0] \u001b[38;5;241m=\u001b[39m res\n\u001b[1;32m    401\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ind \u001b[38;5;129;01min\u001b[39;00m inds:\n\u001b[0;32m--> 402\u001b[0m     buff[ind] \u001b[38;5;241m=\u001b[39m asanyarray(\u001b[43mfunc1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43minarr_view\u001b[49m\u001b[43m[\u001b[49m\u001b[43mind\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, matrix):\n\u001b[1;32m    405\u001b[0m     \u001b[38;5;66;03m# wrap the array, to preserve subclasses\u001b[39;00m\n\u001b[1;32m    406\u001b[0m     buff \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39m__array_wrap__(buff)\n",
      "File \u001b[0;32m~/miniforge3/lib/python3.10/site-packages/scipy/stats/_axis_nan_policy.py:594\u001b[0m, in \u001b[0;36m_axis_nan_policy_factory.<locals>.axis_nan_policy_decorator.<locals>.axis_nan_policy_wrapper.<locals>.hypotest_fun\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result_to_tuple(hypotest_fun_out(\u001b[38;5;241m*\u001b[39msamples, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds))\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 594\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhypotest_fun\u001b[39m(x):\n\u001b[1;32m    595\u001b[0m         samples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msplit(x, split_indices)[:n_samp\u001b[38;5;241m+\u001b[39mn_kwd_samp]\n\u001b[1;32m    596\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m sentinel:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def plot_decision_boundary(model, X, y, title=\"Decision Boundary\", filename=\"decision_boundary.png\"):\n",
    "    # Reduce to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2d = pca.fit_transform(X)\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    \n",
    "    # Make predictions on the mesh grid\n",
    "    Z = model.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    # Plot the decision boundary\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.contourf(xx, yy, Z, alpha=0.4)\n",
    "    scatter = plt.scatter(X_2d[:, 0], X_2d[:, 1], c=y, alpha=0.8)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"First Principal Component\")\n",
    "    plt.ylabel(\"Second Principal Component\")\n",
    "    plt.colorbar(scatter)\n",
    "    \n",
    "    # Save the plot instead of showing it\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()  # Close the figure to free up memory\n",
    "\n",
    "# Assuming x_test and y_test are already defined\n",
    "model = mo.MultiLevelAbstractionKNN(n_neighbors=5, n_levels=3)\n",
    "model.fit(x_test, y_test)\n",
    "plot_decision_boundary(model, x_test, y_test, \"MultiLevelAbstractionKNN Decision Boundary\", \"multilevel_abstraction_knn_decision_boundary.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79a6d554-c23c-4eac-a11c-aefe756df061",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundaries(model1, model2, X, y, title=\"Decision Boundaries Comparison\", filename=\"decision_boundaries.png\"):\n",
    "    # Reduce to 2D for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    X_2d = pca.fit_transform(X)\n",
    "    \n",
    "    # Create a mesh grid\n",
    "    x_min, x_max = X_2d[:, 0].min() - 1, X_2d[:, 0].max() + 1\n",
    "    y_min, y_max = X_2d[:, 1].min() - 1, X_2d[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),\n",
    "                         np.arange(y_min, y_max, 0.1))\n",
    "    \n",
    "    # Make predictions on the mesh grid for both models\n",
    "    Z1 = model1.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z1 = Z1.reshape(xx.shape)\n",
    "    \n",
    "    Z2 = model2.predict(pca.inverse_transform(np.c_[xx.ravel(), yy.ravel()]))\n",
    "    Z2 = Z2.reshape(xx.shape)\n",
    "    \n",
    "    # Create custom colormap\n",
    "    cmap = ListedColormap(['#FF9999', '#66B2FF', '#99FF99'])\n",
    "    \n",
    "    # Plot the decision boundaries\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8), sharex=True, sharey=True)\n",
    "    \n",
    "    # Plot for MultiLevelAbstractionKNN\n",
    "    im1 = ax1.contourf(xx, yy, Z1, cmap=cmap, alpha=0.8)\n",
    "    scatter1 = ax1.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap=cmap, edgecolor='black', linewidth=1)\n",
    "    ax1.set_title(\"MultiLevelAbstractionKNN\")\n",
    "    ax1.set_xlabel(\"First Principal Component\")\n",
    "    ax1.set_ylabel(\"Second Principal Component\")\n",
    "    \n",
    "    # Plot for standard KNN\n",
    "    im2 = ax2.contourf(xx, yy, Z2, cmap=cmap, alpha=0.8)\n",
    "    scatter2 = ax2.scatter(X_2d[:, 0], X_2d[:, 1], c=y, cmap=cmap, edgecolor='black', linewidth=1)\n",
    "    ax2.set_title(\"Standard KNN\")\n",
    "    ax2.set_xlabel(\"First Principal Component\")\n",
    "    ax2.set_ylabel(\"Second Principal Component\")\n",
    "    \n",
    "    # Add legend\n",
    "    classes = np.unique(y)\n",
    "    class_names = [f'Class {i}' for i in classes]\n",
    "    legend1 = ax1.legend(scatter1.legend_elements()[0], class_names, \n",
    "                         loc=\"lower right\", title=\"Classes\")\n",
    "    ax1.add_artist(legend1)\n",
    "    \n",
    "    legend2 = ax2.legend(scatter2.legend_elements()[0], class_names, \n",
    "                         loc=\"lower right\", title=\"Classes\")\n",
    "    ax2.add_artist(legend2)\n",
    "    \n",
    "    plt.suptitle(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(filename, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "# Assuming x_test and y_test are already defined\n",
    "model1 = mo.MultiLevelAbstractionKNN(n_neighbors=5, n_levels=3)\n",
    "model1.fit(x_test, y_test)\n",
    "model2 = KNeighborsClassifier(n_neighbors=5)\n",
    "model2.fit(x_test, y_test)\n",
    "plot_decision_boundaries(model1, model2, x_test, y_test, \"MultiLevelAbstractionKNN vs Standard KNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c05eee-0ce9-4c4f-81f9-075da6f38fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7b0886-0884-455e-ab49-5a4b27e1afaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d4c53-745b-43f6-8882-d7cff3670fe9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4440711-6c51-41ca-aa73-7b6c80565993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e480c6-ba76-4b67-b9d0-3d3d0070eeb7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
